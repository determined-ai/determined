name: pix2pix_facades_adaptive_asha
data:
  base: http://efrosgans.eecs.berkeley.edu/pix2pix/datasets
  dataset: facades
  BUFFER_SIZE: 400
  height: 256
  width: 256
hyperparameters:
  global_batch_size: 1
  discriminator_lr:
    type: log
    base: 10
    minval: -5
    maxval: -4
  discriminator_beta_1:
    type: log
    base: 10
    minval: -1
    maxval: 0
  generator_lr: 
    type: log
    base: 10
    minval: -5
    maxval: -4
  generator_beta_1: 
    type: log
    base: 10
    minval: -1
    maxval: 0
  jitter:
    type: int
    minval: 0
    maxval: 30
  mirror: true
records_per_epoch: 400  # There are 400 images in the facades training set
min_validation_period:
  batches: 40
min_checkpoint_period:
  batches: 400
searcher:
  name: adaptive_asha
  metric: val_total_loss
  smaller_is_better: true
  max_length:
    batches: 4000
  max_trials: 50
entrypoint: model_def:Pix2PixTrial
