{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13d5921a-1fc2-4550-accc-37f9eb2b3698",
   "metadata": {},
   "source": [
    "# Textual Inversion with Determined\n",
    "\n",
    "This notebook generates images from the trained textual inversion models generated with the `detsd.DetStableDiffusionTITrainer` class and saved as Determined checkpoints.  This notebook should be connected to a GPU.\n",
    "\n",
    "### Pre-Launch Setup\n",
    "\n",
    "A [Huggingface User Access Token](https://huggingface.co/docs/hub/security-tokens) is required to download the [Stable Diffusion weights](https://huggingface.co/CompVis/stable-diffusion-v1-4). To use this notebook, please modify the following lines in the `detsd-notebook.yaml` file:\n",
    "```yaml\n",
    "environment:\n",
    "    environment_variables:\n",
    "        - HF_AUTH_TOKEN=YOUR_HF_AUTH_TOKEN_HERE\n",
    "```\n",
    "after which this notebook can be launched by calling the below from the root of the repo directory\n",
    "```bash\n",
    "det -m MASTER_URL_WITH_PORT notebook start --config detsd-notebook.yaml --context .\n",
    "```\n",
    "and then opening up the copy of `textual_inversion.ipynb` on the master.\n",
    "**TODO: Update `--context` arg, don't pull in whole repo unnecessarily**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856fa1e6-5db2-4286-bd80-1a4704725431",
   "metadata": {},
   "source": [
    "Update the jupyter notebook for better progress-bar rendering. Assuming the notebook has dependencies have already been installed via `startup-hook.sh`, which is run upon agent start-up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fa8f48c-ed4f-42b5-926c-a866dbfecfb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -qq jupyterlab-widgets==1.1.1 ipywidgets==7.7.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51aa9437",
   "metadata": {},
   "source": [
    "Import the `DetSDTextualInversionPipeline` class from `detsd.py` (loaded via the `--context flag above), which will be used to generate Stable Diffusion images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3bf573",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detsd import DetSDTextualInversionPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931564e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for logging into the master, if not already logged in.\n",
    "# Not required if notebook was launched as described above.\n",
    "# client.login(master: MASTER_URL, user: USER, password: PASS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fe86f8-01e2-4e26-8d97-76242e42aeee",
   "metadata": {},
   "source": [
    "## Load Determined Checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad13a78-5b21-41ab-bf61-a8dedad5534f",
   "metadata": {},
   "source": [
    "We will now construct the `DetSDTextualInversionPipeline`, incorporating into the model any textual-inversion checkpoints we have trained with `DetStableDiffusionTITrainer`, also contained in `detsd.py`.  These Determined checkpoints can be specified by their uuid, assuming all such checkpoints exist on the master we are currently logged into."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "caefc811-0715-4970-bdc9-d3ffb1d01afc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['learned_embeds.pt', 'metadata.json', 'optimizer_state_dict.pt']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uuids = ['b8e4e741-a770-4359-a301-679b86e5f1f2']\n",
    "detsd_pipeline = DetSDTextualInversionPipeline.from_uuids(uuids,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7120efe6",
   "metadata": {},
   "source": [
    "The above pipeline was constructed using the default settings. In particular, it uses the default `fp16=True` and `autocast=True` options which are used to increase inference speed and reduce memory usage, at the cost of somewhat reduced-quality images.  Other available args can be viewed by uncommenting and running the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fcd13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ? DetSDTextualInversionPipeline.from_uuids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbde91e2",
   "metadata": {},
   "source": [
    "If you have not trained any textual inversion checkpoints and simply want to generate images using the original Stable Diffusion model without custom concepts added, you can leave the `uuids` list below empty or alternatively instantiate the pipeline via\n",
    "```python\n",
    "detsd_pipeline = DetSDTextualInversionPipeline()\n",
    "```\n",
    "which uses the same default arguments as above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb509435",
   "metadata": {},
   "source": [
    "## Generate Images\n",
    "\n",
    "Images can be generated by calling our `detsd_pipeline` instance as in the below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9cbf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a directory in which to save the generated images:\n",
    "! mkdir generated_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68673197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out the concepts we have loaded into the pipeline:\n",
    "detsd_pipeline.concepts\n",
    "first_concept = detsd_pipeline.concepts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f6fa8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = detsd_pipeline(prompt=f'a watercolor painting of a {first_concept}, soft strokes, pastel colors',\n",
    "                      parallelize_factor=2,\n",
    "                      rows=2,\n",
    "                      cols=2,\n",
    "                      num_inference_steps=50,\n",
    "                      seed=2147483647,\n",
    "                      guidance_scale=7.5,\n",
    "                      saved_img_dir='generated_images')\n",
    "imgs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d690d92e-70b3-4986-84f8-2f9b1ec56986",
   "metadata": {},
   "source": [
    "The above generates `num_samples = rows * cols` total samples, tiling them together into a single image.  We generate `parallelize_factor` such samples at a time; reduce `parallelize_factor` to `1` if you are running out of memory.\n",
    "\n",
    "The three args below represent your primary knobs for altering the generated output:\n",
    "* `num_inference_steps`: how many steps to run the generation process for. ~50 is typical\n",
    "* `guidance_scale`: tunes how much weight is given to the prompt during generation. 7.5 is the default, with larger numbers leading to stronger adherence to the prompt.\n",
    "* `generator_seed`: fixed RNG seed for reproducibility\n",
    "\n",
    "Additional arguments can be passed to the underlying Huggingface `StableDiffusionPipeline` instance through the `other_pipeline_call_kwargs` arg. See the [Hugging Face documentation](https://huggingface.co/docs/diffusers/main/en/api/pipelines/stable_diffusion#diffusers.StableDiffusionPipeline.__call__) for information on all available arguments."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 64-bit ('3.8.13')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "274db8ed5a5b9f1d7e673d5dc8f73328ebbaf45fbf7c788fee56d02d0eb8b109"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
