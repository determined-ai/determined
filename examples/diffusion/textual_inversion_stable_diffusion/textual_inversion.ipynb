{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13d5921a-1fc2-4550-accc-37f9eb2b3698",
   "metadata": {},
   "source": [
    "# Textual Inversion with Determined\n",
    "\n",
    "This notebook generates images from the trained textual inversion models generated with the `detsd.DetStableDiffusionTITrainer` class and saved as Determined checkpoints.  This notebook should be connected to a GPU.\n",
    "\n",
    "### Pre-Launch Setup\n",
    "\n",
    "A [Huggingface User Access Token](https://huggingface.co/docs/hub/security-tokens) is required to download the [Stable Diffusion weights](https://huggingface.co/CompVis/stable-diffusion-v1-4). To use this notebook, please modify the following lines in the `detsd-notebook.yaml` file:\n",
    "```yaml\n",
    "environment:\n",
    "    environment_variables:\n",
    "        - HF_AUTH_TOKEN=YOUR_HF_AUTH_TOKEN_HERE\n",
    "```\n",
    "after which this notebook can be launched by calling the below from the root of the repo directory\n",
    "```bash\n",
    "det -m MASTER_URL_WITH_PORT notebook start --config-file detsd-notebook.yaml --context .\n",
    "```\n",
    "and then opening up the copy of `textual_inversion.ipynb` on the master.\n",
    "***TODO: Update `--context` arg, don't pull in whole repo unnecessarily after [#5087](https://github.com/determined-ai/determined/pull/5087) lands***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856fa1e6-5db2-4286-bd80-1a4704725431",
   "metadata": {},
   "source": [
    "Update the jupyter notebook for better progress-bar rendering (may require a re-load to take effect). If the notebook was launched using the above commond, other dependencies were already installed upon agent start-up through the repo's `startup-hook.sh` script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fa8f48c-ed4f-42b5-926c-a866dbfecfb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -qq jupyterlab-widgets==1.1.1 ipywidgets==7.7.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64845227",
   "metadata": {},
   "source": [
    "## Creating the Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51aa9437",
   "metadata": {},
   "source": [
    "Import the `DetSDTextualInversionPipeline` class from `detsd.py` (loaded via the `--context` flag above), which will be used to generate Stable Diffusion images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3bf573",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detsd import DetSDTextualInversionPipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479e93aa",
   "metadata": {},
   "source": [
    "Instantiate the pipeline with the default arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d20e50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "detsd_pipeline = DetSDTextualInversionPipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c6c281",
   "metadata": {},
   "source": [
    "Note: the default arguments set `use_fp16=True` and `use_autocast=True`, which increase inference speed and reduce memory usage, at the cost of somewhat reduced-quality images.  All available args can be viewed by uncommenting and running the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fcd13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ? DetSDTextualInversionPipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fe86f8-01e2-4e26-8d97-76242e42aeee",
   "metadata": {},
   "source": [
    "## Load Determined Checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad13a78-5b21-41ab-bf61-a8dedad5534f",
   "metadata": {},
   "source": [
    "We can now load textual-inversion checkpoints into the model. They are assumed to have been trained with `DetStableDiffusionTITrainer`, also contained in `detsd.py`.  These Determined checkpoints can be specified by their uuid, assuming all such checkpoints exist on the master we are currently logged into."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931564e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for logging into the master, if not already logged in.\n",
    "# Not required if notebook was launched as described above.\n",
    "# client.login(master: MASTER_URL, user: USER, password: PASS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2474acf",
   "metadata": {},
   "source": [
    "Fill in the `uuids` list below with the `uuid` values of any Determined checkpoints you wish to incorporate into the model. If no uuids are provided, images will be generated below using the vanilla Stable Diffusion model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caefc811-0715-4970-bdc9-d3ffb1d01afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "uuids = []\n",
    "detsd_pipeline.load_from_uuids(uuids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb509435",
   "metadata": {},
   "source": [
    "## Generate Images\n",
    "\n",
    "Finally, let's generate some art."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9cbf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a directory in which to save the generated images:\n",
    "! mkdir generated_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68673197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the first concept which was loaded into the pipeline, if any, otherwise falling back to a default:\n",
    "try:\n",
    "    first_concept = detsd_pipeline.all_added_concepts[0]\n",
    "except IndexError:\n",
    "    first_concept = 'orange brain'\n",
    "print(f'Using \"{first_concept}\" as first_concept in the below')\n",
    "print(f'All available concepts: {detsd_pipeline.all_added_concepts}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f6fa8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and inspect images:\n",
    "imgs = detsd_pipeline(prompt=f'a watercolor painting on textured paper of a {first_concept} using soft strokes, pastel colors, incredible composition, masterpiece',\n",
    "                      parallelize_factor=2,\n",
    "                      rows=2,\n",
    "                      cols=2,\n",
    "                      num_inference_steps=50,\n",
    "                      seed=2147483647,\n",
    "                      guidance_scale=7.5,\n",
    "                      saved_img_dir='generated_images')\n",
    "imgs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d690d92e-70b3-4986-84f8-2f9b1ec56986",
   "metadata": {},
   "source": [
    "The above generates `num_samples = rows * cols` total samples, tiling them together into a single image.  We generate `parallelize_factor` such samples at a time; reduce `parallelize_factor` to `1` if you are running out of memory. In general, `num_samples` should be perfectly divisible by `parallelize_factor`, in order to avoid wasted computation.\n",
    "\n",
    "The three args below represent your primary knobs for altering the generated output:\n",
    "* `num_inference_steps`: how many steps to run the generation process for. ~50 is typical\n",
    "* `guidance_scale`: tunes how much weight is given to the prompt during generation. 7.5 is the default, with larger numbers leading to stronger adherence to the prompt.\n",
    "* `generator_seed`: fixed RNG seed for reproducibility\n",
    "\n",
    "Additional arguments can be passed to the underlying Huggingface `StableDiffusionPipeline` instance through the `other_pipeline_call_kwargs` arg. See the [Hugging Face documentation](https://huggingface.co/docs/diffusers/main/en/api/pipelines/stable_diffusion#diffusers.StableDiffusionPipeline.__call__) for information on all available arguments."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 64-bit ('3.8.13')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "274db8ed5a5b9f1d7e673d5dc8f73328ebbaf45fbf7c788fee56d02d0eb8b109"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
