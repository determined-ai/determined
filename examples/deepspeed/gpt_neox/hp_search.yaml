name: gpt-neox-zero-hp-search
debug: false
hyperparameters:
  search_world_size: true
  deepspeed: true
  conf_dir: /gpt-neox/configs
  conf_file:
      - medium.yml
      - determined_cluster.yml
  overwrite_values:
    log_interval: 10
    pipe_parallel_size:
      type:  categorical
      vals:
        - 2
        - 4
        - 8
    model_parallel_size:
      type:  categorical
      vals:
        - 2
        - 4
        - 8
    train_micro_batch_size_per_gpu:
      type:  categorical
      vals:
        - 2
        - 4
        - 8
    train_batch_size: 32
    partition_activations: false
  wandb_group: null
  wandb_team: null
  user_script: null
  eval_tasks: null
environment:
    environment_variables:
        - NCCL_DEBUG=INFO
        # You may need to modify this to match your network configuration.
        - NCCL_SOCKET_IFNAME=ens,eth,ib
    force_pull_image: true
    image:
      gpu: liamdetermined/gpt-neox
resources:
  slots_per_trial: 8
searcher:
  name: grid
  metric: tflops
  smaller_is_better: false
  max_length:
    batches: 100
  max_concurrent_trials: 2
min_validation_period:
    batches: 10
# Disabling checkpointing so that interval time is correct.
checkpoint_policy: none
max_restarts: 2
entrypoint:
  - python3
  - -m
  - determined.launch.deepspeed
  - --trial
  - gpt2_trial:GPT2Trial
