name: gpt-neox-zero1-pipeline-parallel
debug: false
profiling:
    enabled: false
    begin_on_batch: 50
    end_after_batch: 100
    sync_timings: true
hyperparameters:
  search_world_size: false
  conf_dir: /gpt-neox/configs
  conf_file:
      - medium.yml
      - determined_cluster.yml
  overwrite_values:
     pipe_parallel_size: 2
     model_parallel_size: 1
     partition_activations: false
     train_batch_size: 32
     train_micro_batch_size_per_gpu: 2
  wandb_group: null
  wandb_team: null
  user_script: null
  eval_tasks: null
environment:
    environment_variables:
        - NCCL_DEBUG=INFO
        # You may need to modify this to match your network configuration.
        - NCCL_SOCKET_IFNAME=ens,eth,ib
    force_pull_image: true
    image:
      gpu: liamdetermined/gpt-neox
resources:
  slots_per_trial: 8
searcher:
  name: single
  metric: lm_loss
  smaller_is_better: false
  max_length:
    batches: 10000
min_validation_period:
    batches: 1000
max_restarts: 0
entrypoint:
  - python3
  - -m
  - determined.launch.deepspeed
  - --trial
  - gpt2_trial:GPT2Trial
