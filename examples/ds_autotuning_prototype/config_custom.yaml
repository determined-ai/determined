name: minimal_testing
workspace: DS_AT_PROTOTYPING
project: minimal_testing
max_restarts: 0
resources:
  slots_per_trial: 1
searcher:
  name: custom
  max_length: 1e3
  metric: placeholder
hyperparameters:
  dim: 100
  num_records: 1e3
  layers: 3
  ds_config:
    train_micro_batch_size_per_gpu: 128
    gradient_accumulation_steps: 1
    optimizer:
      TYPE: Adam
      params:
        lr: 1e-3
    zero_optimization:
      stage: 0
entrypoint: python3 -m determined.launch.torch_distributed python3 minimal_script.py
