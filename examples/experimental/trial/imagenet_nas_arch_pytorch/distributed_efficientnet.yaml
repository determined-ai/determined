description: imagenet_gaea

# Setting batch size and slots_per_trial.
#   - Nvidia Tesla V100: set batch size to 1024 and slots_per_trial to 8
#   - Nvidia Tesla K80: 
#       - set batch size to 2048 and slots_per_trial to 24
#       - set batch size to 4048 and slots_per_trial to 48

data:
  # Change bucket_name to GCP bucket with imagenet dataset
  # Data folder structure assumed to be imagenet/train and 
  # imagenet/validation for the two data splits.
  #
  # If bucket_name is null, we will run with randomly 
  # generated data.
  bucket_name: determined-ai-datasets 
  # We recommend num_workers_train to be set to 16
  # when running with slots_per_trial=8
  num_workers_train: 16
  num_workers_val: 2
  # If streaming is true, we will send request to bucket
  # every time an image is requested.  If false, we will
  # save data to disk and load that the next time the
  # image is requested.  We recommend streaming=true
  # to avoid having to mount directories to docker container 
  # and guarantee good performance regardless of disk speed.
  streaming: true
  # This folder is only used if streaming is false.
  # This should probably match the container_path
  # in a provided bind mount.
  data_download_dir: null

# Uncomment this if you want to mount a host directory to the 
# docker container.
#bind_mounts:
#  - host_path: /tmp
#    container_path: /mnt/data
#    read_only: false

min_validation_period: 5

hyperparameters:
  num_classes: 1000
  learning_rate: 0.25
  momentum: 0.9
  weight_decay: 1e-5
  drop_path_prob: 0.2
  drop_prob: 0.2
  label_smoothing_rate: 0.1
  ema_decay: 0.999
  clip_gradients_l2_norm: 5
  # Choices include linear, efficientnet, and cosine
  lr_scheduler: efficientnet 
  lr_epochs: 350
  warmup_epochs: 5
  # These HPs only used for efficientnet scheduler
  lr_gamma: 0.975
  lr_decay_every: 2

  init_channels: 48
  layers: 14
  # Batch size may be too big for GPU memory depending
  # on your GPU and number of slots_per_trial.
  global_batch_size: 4096
  auxiliary: false
  auxiliary_weight: 0.4
  randaugment: true
  cutout: true
  cutout_length: 16
  do_SE: true
  activation: swish 

checkpoint_storage:
  save_experiment_best: 5
  save_trial_best: 2
  save_trial_latest: 1

resources:
  slots_per_trial: 48
  shm_size: 30000000000

searcher:
  name: single
  metric: top1_accuracy 
  max_steps: 1000 # 1.2 million images in training set of imagenet
  smaller_is_better: false 

optimizations:
  aggregation_frequency:  1

entrypoint: model_def:ImageNetTrial
