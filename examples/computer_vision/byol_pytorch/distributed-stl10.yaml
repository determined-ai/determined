# STL-10 hyperparameters inspired by this blog post:
# https://generallyintelligent.ai/blog/2020-08-24-understanding-self-supervised-contrastive-learning/

name: stl10_pytorch_const
entrypoint: model_def:BYOLTrial
records_per_epoch: 105000
resources:
  slots_per_trial: 8
  shm_size: 17179869184
min_validation_period:
  epochs: 2

data:
  dataset_name: stl10
  download_dir: /data
  num_workers: 8
  validation_subset_size: 4000
  eval_transform:
    resize_short_edge: 96
    center_crop_size: 96
  train_transform1:
    random_crop_size: 96
    random_crop_min_scale: 0.2
    random_hflip_prob: 0.5
    color_jitter_prob: 0.8
    color_jitter_brightness: 0.4
    color_jitter_contrast: 0.4
    color_jitter_saturation: 0.4
    color_jitter_hue: 0.1
    grayscale_prob: 0.2
    gaussian_blur_prob: 0.5
    gaussian_blur_kernel_size: 9 # Blog post uses a blur transform without set kernel size, so we fall back to ~1/10 image size.
    gaussian_blur_min_std: 0.1
    gaussian_blur_max_std: 2.0
    solarization_prob: 0.0
  train_transform2:
    random_crop_size: 96
    random_crop_min_scale: 0.2
    random_hflip_prob: 0.5
    color_jitter_prob: 0.8
    color_jitter_brightness: 0.4
    color_jitter_contrast: 0.4
    color_jitter_saturation: 0.4
    color_jitter_hue: 0.1
    grayscale_prob: 0.2
    gaussian_blur_prob: 0.5
    gaussian_blur_kernel_size: 9
    gaussian_blur_min_std: 0.1
    gaussian_blur_max_std: 2.0
    solarization_prob: 0.0

hyperparameters:
  training_mode: SELF_SUPERVISED
  validate_with_classifier: true
  backbone_name: resnet18
  global_batch_size: 2048
  classifier:
    learning_rates: [0.4, 0.3, 0.2, 0.1, 0.05]
    logit_clipping:
      enabled: true
      alpha: 20
    logit_regularization_beta: 1e-2
    momentum: 0.9
    train_epochs: 2
  self_supervised:
    lars_eta: 0.001
    momentum: 0.9
    moving_average_decay_base: 0.996
    weight_decay: 1.5e-6
    learning_rate:
      base: 0.2
      base_batch_size: 256
      warmup_epochs: 10

searcher:
  name: single
  metric: test_accuracy
  smaller_is_better: false
  max_length:
    epochs: 100

bind_mounts:
  - host_path: /tmp
    container_path: /data