# Use the latest 2.1 version of CircleCI pipeline process engine. See: https://circleci.com/docs/2.0/configuration-reference
version: 2.1

orbs:
  win: circleci/windows@2.3.0
  slack: circleci/slack@3.4.2
  gke: circleci/gcp-gke@1.1.0
  kubernetes: circleci/kubernetes@0.11.0
  helm: circleci/helm@1.1.2
  gcloud: circleci/gcp-cli@2.1.0
  queue: eddiewebb/queue@volatile

executors:
  python-35:
    docker:
      - image: python:3.5-slim-buster
  python-36:
    docker:
      - image: python:3.6-slim-buster
  python-37:
    docker:
      - image: python:3.7-slim-buster
  python-38:
    docker:
      - image: python:3.8-slim-buster

parameters:
  det-version:
    type: string
    default: 0.14.0.dev0

release-and-rc-filters: &release-and-rc-filters
  branches:
    ignore:
      - /.*/
  tags:
    only:
      - /(\d)+(\.(\d)+)+/
      - /((\d)+(\.(\d)+)+)(rc)(\d)+/

rc-filters: &rc-filters
  branches:
    ignore:
      - /.*/
  tags:
    only:
      - /((\d)+(\.(\d)+)+)(rc)(\d)+/

release-filters: &release-filters
  branches:
    ignore:
      - /.*/
  tags:
    only:
      - /(\d)+(\.(\d)+)+/

upstream-feature-branch: &upstream-feature-branch
  branches:
    ignore:
      - /pull\/.*/
      - /release-.*/
      - master

commands:
  fix-circle-working-directory:
    description: "Fix CIRCLE_WORKING_DIRECTORY"
    steps:
      - run: echo 'CIRCLE_WORKING_DIRECTORY="${CIRCLE_WORKING_DIRECTORY/#\~/$HOME}"' >> $BASH_ENV

  set-slack-user-id:
    steps:
      - run:
          name: Set Slack variables
          command: |
            if ! [ -x "$(command -v jq)" ]; then
              apt update && apt install -y jq
            fi

            AUTHOR_EMAIL="$(git show -s --format='%ae' $CIRCLE_SHA1)"
            echo "export AUTHOR_EMAIL=\"${AUTHOR_EMAIL}\"" >> $BASH_ENV
            LOOKUP_RESPONSE=$(curl -s "https://slack.com/api/users.lookupByEmail?token=${SLACK_API_TOKEN}&email=${AUTHOR_EMAIL}")
            SUCCESS=$(echo "$LOOKUP_RESPONSE" | jq ".ok")
            if [[ "$SUCCESS" == "true" ]]; then
              SLACK_USER_ID=$(echo "$LOOKUP_RESPONSE" | jq -r ".user.id")
              SLACK_NAME=$(echo "$LOOKUP_RESPONSE" | jq -r ".user.name")
              echo "export SLACK_NAME=\"${SLACK_NAME}\"" >> $BASH_ENV
              echo "export SLACK_USER_ID=\"${SLACK_USER_ID}\"" >> $BASH_ENV
            else
              echo "Unable to find Slack user ID for  \"${AUTHOR_EMAIL}\"."
            fi

  pull-task-images:
    parameters:
      tf1:
        type: boolean
        default: false
      tf2:
        type: boolean
        default: false
    steps:
      - when:
          condition: <<parameters.tf1>>
          steps:
            - run: docker pull determinedai/environments:py-3.6.9-pytorch-1.4-tf-1.15-cpu-067db2b
      - when:
          condition: <<parameters.tf2>>
          steps:
            - run: docker pull determinedai/environments:py-3.6.9-pytorch-1.4-tf-2.2-cpu-067db2b

  login-docker:
    steps:
      - run: echo "${DOCKER_PASS}" | docker login --username ${DOCKER_USER} --password-stdin

  install-protoc:
    steps:
      - run: curl -o /tmp/protoc.zip -L https://github.com/protocolbuffers/protobuf/releases/download/v3.12.1/protoc-3.12.1-linux-x86_64.zip
      - run: unzip /tmp/protoc.zip -d $HOME/.local

  setup-go-intg-deps:
    steps:
      - install-protoc # Install newer version of protoc into $HOME/.local/bin, since default is proto2.
      - run: PATH=$HOME/.local/bin:$PATH make -C proto get-deps
      - run: PATH=$HOME/.local/bin:$PATH make -C proto build
      - run: make -C master get-deps
      - run: make -C agent get-deps
      - run: make -C tools start-db

  go-get-deps:
    steps:
      - install-protoc
      - restore_cache:
          keys:
            - det-go-deps-v1dev7-{{ checksum  "master/go.sum" }}-{{ checksum  "agent/go.sum" }}-{{ checksum  "proto/go.sum" }}
      - run: make -C proto get-deps
      - run: make -C master get-deps
      - run: make -C agent get-deps
      - save_cache:
          key: det-go-deps-v1dev7-{{ checksum  "master/go.sum" }}-{{ checksum  "agent/go.sum" }}-{{ checksum  "proto/go.sum" }}
          paths:
            - "/home/circleci/go/pkg/mod/"
  react-get-deps:
    steps:
      - attach_workspace:
          at: .
      - run: make -C webui/api-ts-sdk get-deps-package
      - run: make -C webui/api-ts-sdk build-package
      - restore_cache:
          keys:
            - det-react-deps-v1dev3-{{ checksum  "webui/react/package-lock.json" }}
      - run:
          name: Get React dependencies
          command: |
            make -C webui/react get-deps-api
            if [ ! -d "webui/react/node_modules" ]; then
              make -C webui/react get-deps-npm
            fi
      - save_cache:
          key: det-react-deps-v1dev3-{{ checksum  "webui/react/package-lock.json" }}
          paths:
            - "webui/react/node_modules"

  install-wheel:
    parameters:
      package-name:
        type: string
      package-location:
        type: string
    steps:
      - run:
          name: Install <<parameters.package-name>>
          working_directory: <<parameters.package-location>>
          command: |
            make build
            pip install --find-links dist <<parameters.package-name>>==<< pipeline.parameters.det-version >>
            pip install --no-deps --force-reinstall --find-links dist <<parameters.package-name>>==<< pipeline.parameters.det-version >>
  setup-python-venv:
    description: Set up and create Python venv.
    parameters:
      determined:
        type: boolean
        default: false
      determined-common:
        type: boolean
        default: false
      determined-cli:
        type: boolean
        default: false
      determined-deploy:
        type: boolean
        default: false
      extras-requires:
        type: string
        default: ""
      extra-requirements-file:
        type: string
        default: ""
      executor:
        type: string
    steps:
      - run:
          name: Setup venv
          command: |
            python3.6 -m venv /tmp/venv
            echo "export PATH=/tmp/venv/bin:\"${PATH}\"" >> $BASH_ENV
            /tmp/venv/bin/python -m pip install --upgrade pip\<20 wheel setuptools

      - run:
          name: Write cache key
          command: |
            echo <<parameters.executor>> > /tmp/cachefile
            if [ "<<parameters.determined-common>>" = "true" ]; then
              cat common/setup.py >> /tmp/cachefile
            fi
            if [ "<<parameters.determined>>" = "true" ]; then
              cat harness/setup.py >> /tmp/cachefile
            fi
            if [ "<<parameters.determined-cli>>" = "true" ]; then
              cat cli/setup.py >> /tmp/cachefile
            fi
            if [ "<<parameters.determined-deploy>>" = "true" ]; then
              cat deploy/setup.py >> /tmp/cachefile
            fi
            echo <<parameters.extras-requires>> >> /tmp/cachefile
            if [ -n <<parameters.extra-requirements-file>> ]; then
              cat <<parameters.extra-requirements-file>> >> /tmp/cachefile
            fi

      - restore_cache:
          keys:
            - det-python-deps-v1dev2-{{ checksum "/tmp/cachefile" }}
      - when:
          condition: <<parameters.determined-common>>
          steps:
            - install-wheel:
                package-name: determined-common
                package-location: ~/project/common
      - when:
          condition: <<parameters.determined-cli>>
          steps:
            - install-wheel:
                package-name: determined-cli
                package-location: ~/project/cli
      - when:
          condition: <<parameters.determined>>
          steps:
            - install-wheel:
                package-name: determined
                package-location: ~/project/harness
      - when:
          condition: <<parameters.determined-deploy>>
          steps:
            - install-wheel:
                package-name: determined-deploy
                package-location: ~/project/deploy
      - run:
          name: Install <<parameters.extras-requires>>
          command: |
            if [ -n "<<parameters.extras-requires>>" ]; then
              pip install <<parameters.extras-requires>>
            fi
      - run:
          name: Install <<parameters.extra-requirements-file>>
          command: |
            if [ -n "<<parameters.extra-requirements-file>>" ]; then
              pip install -r <<parameters.extra-requirements-file>>
            fi
      - save_cache:
          key: det-python-deps-v1dev2-{{ checksum "/tmp/cachefile" }}
          paths:
            - "/tmp/venv"
      - run: python --version
      - run: pip --version
      - run: pip freeze
      # Allow this to fail, but it is useful for debugging.
      - run: sh -c "pip check || true"

  run-e2e-tests:
    parameters:
      mark:
        type: string
        default: ""
      junit-path:
        type: string
        default: "/tmp/test-results/e2e/tests.xml"
      master-scheme:
        type: string
        default: "http"
      master-host:
        type: string
        default: "localhost"
      master-port:
        type: string
        default: "8080"
      master-cert:
        type: string
        default: ""
      master-cert-name:
        type: string
        default: ""
    steps:
      - run:
          name: Split tests
          working_directory: ~/project/e2e_tests
          command: |
            # If a test mark is specified, preselect only files that contain tests with that mark to
            # minimize how wrong CircleCI's splitting can get things.
            if [ -n "<<parameters.mark>>" ]; then
              find tests -name 'test*.py' -print0 | xargs -0 grep -rl 'pytest\.mark\.<<parameters.mark>>'
            else
              circleci tests glob 'tests/**/test*.py'
            fi | circleci tests split --split-by=timings > /tmp/tests-to-run
            echo "Running tests from these files:"
            sed 's/^/- /' </tmp/tests-to-run

      - wait-for-master:
          scheme: <<parameters.master-scheme>>
          host: <<parameters.master-host>>
          port: <<parameters.master-port>>

      - run:
          name: Run e2e tests
          working_directory: ~/project/e2e_tests
          command: |
            DET_MASTER_CERT_FILE=<<parameters.master-cert>> DET_MASTER_CERT_NAME=<<parameters.master-cert-name>> \
            pytest -vv -s \
            -m '<<parameters.mark>>' \
            --durations=0 \
            --master-scheme="<<parameters.master-scheme>>" \
            --master-host="<<parameters.master-host>>" \
            --master-port="<<parameters.master-port>>" \
            -o junit_family=xunit1 \
            --junit-xml="<<parameters.junit-path>>" \
            $(< /tmp/tests-to-run)

  run-det-deploy-tests:
    parameters:
      mark:
        type: string
        default: ""
      det-version:
        type: string
        default: ""
    steps:
      - run:
          name: Run det-deploy tests
          working_directory: ~/project/e2e_tests
          command: |
            pytest -vv -s \
            -m <<parameters.mark>> \
            --det-version="<<parameters.det-version>>"

  deploy-aws-cluster:
    parameters:
      cluster-id:
        type: string
      det-version:
        type: string
      keypair:
        type: string
        default: "integrations-test"
      enable-cors:
        type: boolean
        default: false
      master-tls-cert:
        type: string
        default: ""
      master-tls-key:
        type: string
        default: ""
      master-cert-name:
        type: string
        default: ""
      cpu-agent-instance-type:
        type: string
        default: "m5.large"
      gpu-agent-instance-type:
        type: string
        default: "p2.xlarge"
      max-dynamic-agents:
        type: integer
        default: 1
      retain-log-group:
        type: boolean
        default: false
      log-group-prefix:
        type: string
        default: ""
    steps:
      - run:
          name: Initialize extra arguments
          command: touch /tmp/det-deploy-extra-args
      - when:
          condition:
            equal:
               [ true, << parameters.enable-cors >> ]
          steps:
          - run:
              name: Enable CORS
              command: 'echo --enable-cors >> /tmp/det-deploy-extra-args'

      - run:
          name: Configure TLS arguments
          command: |
            if [ -n "<<parameters.master-tls-cert>>" ]; then echo "--master-tls-cert <<parameters.master-tls-cert>>" >> /tmp/det-deploy-extra-args; fi
            if [ -n "<<parameters.master-tls-key>>" ]; then echo "--master-tls-key <<parameters.master-tls-key>>" >> /tmp/det-deploy-extra-args; fi
            if [ -n "<<parameters.master-cert-name>>" ]; then echo "--master-cert-name <<parameters.master-cert-name>>" >> /tmp/det-deploy-extra-args; fi
      - run:
          name: Configure log group arguments
          command: |
            if [ <<parameters.retain-log-group>> ]; then echo "--retain-log-group" >> /tmp/det-deploy-extra-args; fi
            if [ -n "<<parameters.log-group-prefix>>" ]; then echo "--log-group-prefix <<parameters.log-group-prefix>>" >> /tmp/det-deploy-extra-args; fi
      - run:
          name: Deploy AWS cluster
          command: |
            echo "-----BEGIN ARGS-----"
            cat /tmp/det-deploy-extra-args
            echo "-----END ARGS-----"
            det-deploy aws up \
              $(< /tmp/det-deploy-extra-args) \
              --cluster-id <<parameters.cluster-id>> \
              --det-version <<parameters.det-version>> \
              --cpu-agent-instance-type <<parameters.cpu-agent-instance-type>> \
              --gpu-agent-instance-type <<parameters.gpu-agent-instance-type>> \
              --max-dynamic-agents <<parameters.max-dynamic-agents>> \
              --keypair <<parameters.keypair>>
  terminate-aws-cluster:
    parameters:
      cluster-id:
        type: string
    steps:
      - run:
          name: Terminate AWS Cluster
          when: always
          command: |
            det-deploy aws down \
              --cluster-id <<parameters.cluster-id>>

  setup-aws-cluster:
    parameters:
      cluster-id:
        type: string
      det-version:
        type: string
      gpu-agent-instance-type:
        type: string
        default: "p2.xlarge"
      cpu-agent-instance-type:
        type: string
        default: "m5.large"
      max-dynamic-agents:
        type: integer
        default: 1
      master-tls-cert:
        type: string
      master-tls-key:
        type: string
      master-cert-name:
        type: string
    steps:
      - set-cluster-id:
          cluster-id: <<parameters.cluster-id>>
      - deploy-aws-cluster:
          cluster-id: ${CLUSTER_ID}
          det-version: <<parameters.det-version>>
          cpu-agent-instance-type: <<parameters.cpu-agent-instance-type>>
          gpu-agent-instance-type: <<parameters.gpu-agent-instance-type>>
          max-dynamic-agents: <<parameters.max-dynamic-agents>>
          master-tls-cert: <<parameters.master-tls-cert>>
          master-tls-key: <<parameters.master-tls-key>>
          master-cert-name: <<parameters.master-cert-name>>
          log-group-prefix: determined-ci
          retain-log-group: true
      - set-master-address-aws:
          cluster-id: ${CLUSTER_ID}
          master-tls-cert: <<parameters.master-tls-cert>>
          master-tls-key: <<parameters.master-tls-key>>
      - wait-for-master:
          scheme: ${MASTER_SCHEME:-http}
          host: ${MASTER_HOST}
          port: ${MASTER_PORT:-8080}

  terminate-gke-cluster:
    parameters:
      cluster-id:
        type: string
      region:
        type: string
    steps:
      # Use a run instead of `gke/delete-cluster` because circle CI orbs do not support `when`.
      - run:
          name: Terminate GKE Cluster
          when: always
          command: |
            gcloud container clusters delete <<parameters.cluster-id>> --quiet --region=<<parameters.region>>

  terminate-gke-cluster-cuda-11:
    parameters:
      cluster-id:
        type: string
      zone:
        type: string
    steps:
      # Use a run instead of `gke/delete-cluster` because circle CI orbs do not support `when`.
      - run:
          name: Terminate GKE Cluster
          when: always
          command: |
            gcloud container clusters delete <<parameters.cluster-id>> --quiet --zone=<<parameters.zone>>

  setup-gke-cluster:
    parameters:
      cluster-id:
        type: string
      det-version:
        type: string
      gke-version:
        type: string
      machine-type:
        type: string
      num-machines:
        type: integer
      gpu-type:
        type: string
      gpus-per-machine:
        type: integer
      region:
        type: string
      node-locations:
        type: string
    steps:
      - set-cluster-id:
          cluster-id: <<parameters.cluster-id>>
      - gke/create-cluster:
          cluster: ${CLUSTER_ID}
          perform-login: true
          install-kubectl: true
          additional-args: |
            --cluster-version=<<parameters.gke-version>> \
            --machine-type=<<parameters.machine-type>> \
            --num-nodes=<<parameters.num-machines>> \
            --accelerator type=<<parameters.gpu-type>>,count=<<parameters.gpus-per-machine>> \
            --region=<<parameters.region>> \
            --node-locations=<<parameters.node-locations>> \
            --scopes=storage-rw \
            --image-type=UBUNTU
      - kubernetes/create-or-update-resource:
          resource-file-path: .circleci/scripts/gpu-daemonset.yaml
      - helm/install-helm-chart:
          chart: helm/charts/determined
          helm-version: v3.2.4
          namespace: "default"
          wait: true
          release-name: "ci"
          values-to-override: |
            detVersion=<<parameters.det-version>>,\
            maxSlotsPerPod=<<parameters.gpus-per-machine>>,\
            checkpointStorage.type=gcs,\
            checkpointStorage.bucket=det-ci
      - set-master-address-gke:
          release-name: "ci"
          namespace: "default"

  setup-gke-cluster-cuda-11:
    parameters:
      cluster-id:
        type: string
      det-version:
        type: string
      gke-version:
        type: string
      machine-type:
        type: string
      num-machines:
        type: integer
      gpu-type:
        type: string
      gpus-per-machine:
        type: integer
      node-locations:
        type: string
      release-channel:
        type: string
        default: rapid
      gcloud-service-key:
        default: GCLOUD_SERVICE_KEY
        description: The gcloud service key
        type: env_var_name
      google-compute-zone:
        default: GOOGLE_COMPUTE_ZONE
        description: The Google compute zone to connect with via the gcloud CLI
        type: env_var_name
      google-project-id:
        default: GOOGLE_PROJECT_ID
        description: The Google project ID to connect with via the gcloud CLI
        type: env_var_name
    steps:
      - set-cluster-id:
          cluster-id: <<parameters.cluster-id>>
      - gcloud/install:
          version: "319.0.0"
      - kubernetes/install-kubectl
      - gcloud/initialize:
          gcloud-service-key: <<parameters.gcloud-service-key>>
          google-compute-zone: <<parameters.google-compute-zone>>
          google-project-id: <<parameters.google-project-id>>
      - run:
          command: gcloud beta container clusters create ${CLUSTER_ID} --addons=HorizontalPodAutoscaling,HttpLoadBalancing,Istio,CloudRun,NodeLocalDNS --machine-type=n1-standard-8 --cluster-version=<<parameters.gke-version>> --zone=us-central1-c --release-channel rapid --node-locations=us-central1-c --subnetwork=default --enable-stackdriver-kubernetes --scopes storage-rw,cloud-platform --num-nodes 1
          name: Create GKE cluster
      - run:
          command: gcloud container clusters get-credentials ${CLUSTER_ID} --project determined-ai --zone <<parameters.node-locations>>
          name: Get Kubeconfig
      - run:
          command: gcloud container node-pools create accel --project determined-ai --zone <<parameters.node-locations>> --cluster ${CLUSTER_ID} --num-nodes <<parameters.num-machines>> --accelerator type=<<parameters.gpu-type>>,count=<<parameters.gpus-per-machine>> --machine-type=<<parameters.machine-type>> --enable-autorepair --disk-size=100 --scopes cloud-platform --verbosity error
          name: Create GPU node pool
      - run:
          command: kubectl apply -f https://raw.githubusercontent.com/GoogleCloudPlatform/container-engine-accelerators/master/nvidia-driver-installer/cos/daemonset-preloaded.yaml
          name: Install NVIDIA drivers
      - run:
          command: kubectl create clusterrolebinding cluster-admin-binding --clusterrole cluster-admin --user "$(gcloud config get-value account)"
          name: Setup cluster role binding
      - helm/install-helm-chart:
          chart: helm/charts/determined
          helm-version: v3.2.4
          namespace: "default"
          wait: true
          release-name: "ci"
          values-to-override: |
            detVersion=<<parameters.det-version>>,\
            maxSlotsPerPod=<<parameters.gpus-per-machine>>,\
            taskContainerDefaults.cpuImage=determinedai/environments:cuda-11.0-pytorch-1.7-tf-2.4-gpu-0.9.0,\
            taskContainerDefaults.gpuImage=determinedai/environments:cuda-11.0-pytorch-1.7-tf-2.4-gpu-0.9.0,\
            checkpointStorage.type=gcs,\
            checkpointStorage.bucket=det-ci
      - set-master-address-gke:
          release-name: "ci"
          namespace: "default"

  install-webui-test-deps:
    steps:
      - run: |
          . /opt/circleci/.nvm/nvm.sh
          nvm install v12
          nvm alias default v12
          make -C webui/tests get-deps
      - run: docker pull determinedai/gauge-taiko-ts

  setup-local-cluster:
    parameters:
      det-version:
        type: string
    steps:
      - run: det-deploy local cluster-up --no-gpu --delete-db --det-version <<parameters.det-version>>

  dump-local-cluster-logs:
    steps:
      - run:
          name: Dump det-deploy logs
          when: always
          command: det-deploy local logs --no-follow

  run-e2e-webui-tests:
    steps:
      - run: python webui/tests/bin/createUserAndExperiments.py
      - run: |
          mkdir -p webui/tests/reports/logs
          mkdir -p webui/tests/reports/videos
          docker run \
            --name e2e_gauge \
            --network=determined_default \
            --mount type=bind,source=$(pwd)/webui,target=/webui \
            -w /webui/tests \
            --env DET_MASTER=determined-master:8080 \
            determinedai/gauge-taiko-ts
          rm -f webui/tests/reports/videos/*.jpeg

  generate-tls-cert:
    steps:
      - run: |
          .circleci/scripts/generate_cert.sh /tmp/master
          echo 'export MASTER_TLS_CERT=/tmp/master.crt MASTER_TLS_KEY=/tmp/master.key MASTER_CERT_NAME=determined-master-ci' >> $BASH_ENV

  set-master-address-aws:
    parameters:
      cluster-id:
        type: string
      master-tls-cert:
        type: string
      master-tls-key:
        type: string
    steps:
      - run: |
          MASTER_HOST=$(python .circleci/scripts/get_output_from_stack.py <<parameters.cluster-id>> DeterminedAddress)
          echo "export MASTER_HOST=\"${MASTER_HOST}\"" >> $BASH_ENV

      - run: |
          if [ -n "<<parameters.master-tls-cert>>" ] && [ -n "<<parameters.master-tls-key>>" ]; then
            echo "export MASTER_PORT=8443" >> $BASH_ENV
            echo "export MASTER_SCHEME=https" >> $BASH_ENV
          fi

  set-master-address-gke:
    parameters:
      release-name:
        type: string
      namespace:
        type: string
    steps:
      - run:
          name: Set Master Address
          command: |
            MASTER_HOST=$(kubectl get -n <<parameters.namespace>>  service determined-master-service-<<parameters.release-name>> \
            --output jsonpath='{.status.loadBalancer.ingress[0].ip}')
            echo "export MASTER_HOST=\"${MASTER_HOST}\"" >> $BASH_ENV
            echo "${MASTER_HOST}"

  set-google-application-credentials:
    steps:
      - run:
          name: Set Google Application Credentials
          command: |
            GOOGLE_APPLICATION_CREDENTIALS=${HOME}/gcloud-service-key.json
            echo "export GOOGLE_APPLICATION_CREDENTIALS=\"${GOOGLE_APPLICATION_CREDENTIALS}\"" >> $BASH_ENV

  set-cluster-id:
    parameters:
      cluster-id:
        type: string
    steps:
      - run: echo "export CLUSTER_ID=\"<<parameters.cluster-id>>\"" >> $BASH_ENV

  wait-for-master:
    parameters:
      scheme:
        type: string
        default: "http"
      host:
        type: string
      port:
        type: string
        default: "8080"
    steps:
      - run: python .circleci/scripts/wait_for_master.py <<parameters.scheme>>://<<parameters.host>>:<<parameters.port>>

  locate-cloudwatch-logs:
    parameters:
      cluster-id:
        type: string
      region:
        type: string
        default: us-west-2
    steps:
      - run:
          name: Locate CloudWatch logs
          when: always
          command: |
            LOG_GROUP=$(python .circleci/scripts/get_output_from_stack.py <<parameters.cluster-id>> LogGroup)
            echo "Cluster logs can be found in CloudWatch under the log group $LOG_GROUP"
            echo "or the URL below (if the log group is in your default region):"
            ENC_LOG_GROUP=$(echo "$LOG_GROUP" | sed 's|/|$252F|g')
            echo "https://console.aws.amazon.com/cloudwatch/home#logsV2:log-groups/log-group/$ENC_LOG_GROUP"


jobs:
  build-docs:
    docker:
      - image: determinedai/cimg-base:stable
    steps:
      - checkout
      - setup-python-venv:
          determined-common: true
          determined-cli: true
          determined: true
          extras-requires: "tensorflow==1.14 torch==1.4"
          extra-requirements-file: "docs/requirements.txt"
          executor: determinedai/cimg-base:stable
      - run: make -C examples build
      - run: make -C helm build
      - attach_workspace:
          at: .
      - run: make -C docs build
      - persist_to_workspace:
          root: .
          paths:
            - examples/build
            - helm/build
            - cli/dist
            - common/dist
            - harness/dist
            - docs/site/html
      - store_artifacts:
          path: docs/site/html

  publish-docs:
    docker:
      - image: hashicorp/terraform:light
    steps:
      - checkout
      - attach_workspace:
          at: .
      - run: apk add make curl python3 py3-pip
      - run: pip3 install awscli
      - run: make -C docs publish

  package-and-push-system-local:
    docker:
      - image: cimg/go:1.15
        environment:
          GO111MODULE: "on"
    resource_class: medium+
    steps:
      - checkout
      - attach_workspace:
          at: .
      - go-get-deps
      - setup_remote_docker:
          version: 19.03.12
      - run: make -C proto build
      - run: make package
      - run: mkdir -p build/
      - run: docker save -o build/master.image determinedai/determined-master:${CIRCLE_SHA1}
      - run: docker save -o build/agent.image determinedai/determined-agent:${CIRCLE_SHA1}
      - persist_to_workspace:
          root: .
          paths:
            - "master/dist/*linux_amd64.deb"
            - "master/dist/*linux_amd64.rpm"
            - "agent/dist/*linux_amd64.deb"
            - "agent/dist/*linux_amd64.rpm"
            - "build/*.image"

  package-and-push-system-dev:
    docker:
      - image: cimg/go:1.15
        environment:
          GO111MODULE: "on"
    resource_class: medium+
    steps:
      - checkout
      - attach_workspace:
          at: .
      - go-get-deps
      - setup_remote_docker:
          version: 19.03.12
      - run: make -C proto build
      - run: make package
      - login-docker
      - run: make -C master publish-dev
      - run: make -C agent publish-dev

  package-and-push-system-rc:
    docker:
      - image: cimg/go:1.15
        environment:
          GO111MODULE: "on"
    resource_class: medium+
    steps:
      - checkout
      - attach_workspace:
          at: .
      - go-get-deps
      - setup_remote_docker:
          version: 19.03.12
      - run: make -C proto build
      - run: make package
      - login-docker
      - run: make -C master publish
      - run: make -C agent publish

  package-and-push-system-release:
    docker:
      - image: cimg/go:1.15
        environment:
          GO111MODULE: "on"
    resource_class: medium+
    steps:
      - checkout
      - attach_workspace:
          at: .
      - go-get-deps
      - setup_remote_docker:
          version: 19.03.12
      - login-docker
      - run: make -C proto build
      - run: make -C master release
      - run: make -C agent release

  publish-python-package:
    parameters:
      path:
        type: string
    docker:
      - image: determinedai/cimg-base:stable
    steps:
      - checkout
      - setup-python-venv:
          extras-requires: "twine"
          executor: determinedai/cimg-base:stable
      - run: make -C <<parameters.path>> build
      - run: make -C <<parameters.path>> publish

  build-and-package-ts-sdk:
    docker:
      - image: cimg/openjdk:14.0.1
    steps:
      - checkout
      - attach_workspace:
          at: .
      - run: make -C webui/api-ts-sdk get-deps-swagger
      - run: make -C webui/api-ts-sdk build-swagger
      - persist_to_workspace:
          root: .
          paths:
            - webui/api-ts-sdk/src

  upload-try-now-template:
    docker:
      - image: determinedai/cimg-base:stable
    steps:
      - checkout
      - setup-python-venv:
          extras-requires: "awscli"
          executor: determinedai/cimg-base:stable
      - run: make -C deploy upload-try-now-template

  test-debian-packaging:
    machine:
      image: ubuntu-1604:202004-01
    steps:
      - checkout
      - attach_workspace:
          at: .
      - run: sudo apt-get install -y $(pwd)/master/dist/determined-master*.deb
      - run: sudo apt-get install -y $(pwd)/agent/dist/determined-agent*.deb
      - run: sudo cp .circleci/packaging/master.yaml /etc/determined/master.yaml
      - run: sudo cp .circleci/packaging/agent.yaml /etc/determined/agent.yaml
      - run: make -C tools start-db
      - run: python3 .circleci/scripts/wait_for_server.py localhost 5432
      - run: sudo systemctl restart determined-master
      - run: python3 .circleci/scripts/wait_for_server.py localhost 8080
      - run: sudo systemctl restart determined-agent
      - run: ./.circleci/scripts/sanity.sh

  test-e2e-webui:
    machine:
      image: ubuntu-1604:202004-01
    resource_class: large
    steps:
      - checkout
      - attach_workspace:
          at: .
      - run: docker load --input build/master.image
      - run: docker load --input build/agent.image

      - install-webui-test-deps
      - run: pyenv global 3.6.10
      - setup-python-venv:
          determined-common: true
          determined-cli: true
          determined-deploy: true
          extra-requirements-file: "webui/tests/requirements.txt"
          executor: ubuntu-1604:202004-01
      - setup-local-cluster:
          det-version: ${CIRCLE_SHA1}
      - run-e2e-webui-tests
      - dump-local-cluster-logs
      - store_test_results:
          path: webui/tests/reports/xml-report/
      - store_artifacts:
          path: webui/tests/reports/

  lint-react:
    docker:
      - image: cimg/node:12.16
    steps:
      - checkout
      - react-get-deps
      - run: make -C webui/react check

  build-react-preview:
    docker:
      - image: cimg/node:12.16
    environment:
      PUBLIC_URL: /0
      SERVER_ADDRESS: http://localhost:8080
    steps:
      - checkout
      - react-get-deps
      - run: make -C webui/react build
      - store_artifacts:
          path: webui/react/build
          destination: /

  build-react:
    parameters:
      dev-mode:
        type: boolean
        default: false
    docker:
      - image: cimg/node:12.16
    steps:
      - checkout
      - react-get-deps
      - run: |
            if <<parameters.dev-mode>>; then
              echo 'Setting development mode...'
              export DET_NODE_ENV=development
            fi
            make -C webui/react build
      - persist_to_workspace:
          root: .
          paths:
            - webui/react/build

  test-unit-react:
    docker:
      - image: cimg/node:12.16
    steps:
      - checkout
      - react-get-deps
      - run: make -C webui/react test

  build-storybook:
    docker:
      - image: cimg/node:12.16
    steps:
      - checkout
      - react-get-deps
      - run: make -C webui/react build-storybook
      - store_artifacts:
          path: webui/react/build-storybook

  lint-go:
    docker:
      - image: cimg/go:1.15
        environment:
          GO111MODULE: "on"
    steps:
      - checkout
      - go-get-deps
      - run: sudo apt-get update && sudo apt-get install -y clang-format
      - run: make -C proto build
      - run: make -C proto check
      - run: make -C master check
      - run: make -C agent check

  build-go:
    docker:
      - image: cimg/go:1.15
        environment:
          GO111MODULE: "on"
    steps:
      - checkout
      - go-get-deps
      - run: make -C proto build
      - run: make -C master build
      - run: make -C agent build
      - persist_to_workspace:
          root: .
          paths:
            - "master/build"
            - "agent/build"

  build-proto:
    docker:
      - image: cimg/go:1.15
        environment:
          GO111MODULE: "on"
    steps:
      - checkout
      - go-get-deps
      - run: make -C proto build
      - persist_to_workspace:
          root: .
          paths:
            - "proto/build/**/*"

  test-unit-go:
    docker:
      - image: cimg/go:1.15
        environment:
          GO111MODULE: "on"
    steps:
      - checkout
      - go-get-deps
      - run: make -C proto build
      - run: make -C master test
      - run: make -C agent test

  test-intg-master:
    machine:
      image: ubuntu-1604:202004-01
    resource_class: large
    steps:
      - checkout
      - attach_workspace:
          at: .
      - setup-go-intg-deps
      - run: make -C master test-intg

  test-intg-agent:
    machine:
      image: ubuntu-1604:202004-01
    resource_class: large
    steps:
      - checkout
      - attach_workspace:
          at: .
      - setup-go-intg-deps
      - run: make -C agent test-intg

  lint-docs:
    docker:
      - image: determinedai/cimg-base:stable
    steps:
      - checkout
      - setup-python-venv:
          extra-requirements-file: "docs/requirements.txt"
          executor: determinedai/cimg-base:stable
      - run: make -C docs check

  lint-python:
    docker:
      - image: determinedai/cimg-base:stable
    steps:
      - checkout
      - setup-python-venv:
          determined-common: true
          determined-cli: true
          determined: true
          determined-deploy: true
          extras-requires: "torch==1.4.0"
          extra-requirements-file: "requirements.txt"
          executor: determinedai/cimg-base:stable
      - run: make -C cli check
      - run: make -C common check
      - run: make -C harness check
      - run: make -C deploy check
      - run: make -C e2e_tests check
      - run: make -C examples check
      - run: make -C tools check

  test-unit-harness:
    docker:
      - image: determinedai/cimg-base:stable
    steps:
      - checkout
      - setup-python-venv:
          determined-common: true
          determined: true
          extras-requires: "tensorflow==1.14.0 torch==1.4.0 torchvision==0.5.0"
          extra-requirements-file: "harness/tests/requirements.txt"
          executor: determinedai/cimg-base:stable
      - run: make -C harness test

  test-unit-harness-tf2:
    docker:
      - image: determinedai/cimg-base:stable
    steps:
      - checkout
      - setup-python-venv:
          determined-common: true
          determined: true
          extras-requires: "tensorflow==2.2.0"
          extra-requirements-file: "harness/tests/requirements.txt"
          executor: determinedai/cimg-base:stable
      - run: make -C harness test-tf2

  test-examples:
    docker:
      - image: determinedai/cimg-base:stable
    steps:
      - checkout
      - setup-python-venv:
          determined-common: true
          determined: true
          determined-cli: true
          extra-requirements-file: "examples/tests/requirements.txt"
          executor: determinedai/cimg-base:stable
      - run: make -C examples test

  test-cli:
    parameters:
      executor-name:
        type: string
    executor: << parameters.executor-name >>
    steps:
      - checkout
      - run: python --version
      - run: pip --version
      - run: pip install wheel
      - run: cd common; python setup.py bdist_wheel -d ../build
      - run: cd cli; python setup.py bdist_wheel -d ../build
      # Windows needs special treatment of cryptography for unknown reasons.
      - run: sh -c "if which conda ; then conda install cryptography --yes ; fi"
      - run: pip install --find-links build determined-cli==<< pipeline.parameters.det-version >>
      - run: pip freeze
      # Allow this to fail, but it is useful for debugging.
      - run: sh -c "pip check || true"
      # Ensure Determined cli can run without installing cli test requirements
      - run: det --help
      - run: pip install setuptools_scm
      - run: pip install -r cli/tests/requirements.txt
      - run: pip freeze
      - run: sh -c "pip check || true"
      - run: pytest cli/tests

  test-e2e:
    parameters:
      tf1:
        type: boolean
        default: false
      tf2:
        type: boolean
        default: false
      mark:
        type: string
      parallelism:
        type: integer
    machine:
      image: ubuntu-1604:202004-01
    resource_class: large
    parallelism: <<parameters.parallelism>>
    steps:
      - checkout
      - attach_workspace:
          at: .

      - run: pyenv global 3.6.10
      - setup-python-venv:
          determined-common: true
          determined-cli: true
          determined: true
          determined-deploy: true
          extra-requirements-file: "e2e_tests/tests/requirements.txt"
          executor: ubuntu-1604:202004-01

      - run:
          name: Start database
          command: make -C tools start-db
      - run:
          name: Start cluster
          command: make -C tools run
          background: true

      - pull-task-images:
          tf1: <<parameters.tf1>>
          tf2: <<parameters.tf2>>

      - run-e2e-tests:
          mark: <<parameters.mark>>
          master-host: localhost

      - store_test_results:
          path: /tmp/test-results/

  deploy:
    parameters:
      gpu-agent-instance-type:
        type: string
        default: "p2.xlarge"
      cpu-agent-instance-type:
        type: string
        default: "m5.large"

      max-dynamic-agents:
        type: integer
        default: 1
      enable-cors:
        type: boolean
        default: false
    docker:
      - image: determinedai/cimg-base:stable
    steps:
      - queue/until_front_of_line:
          only-on-branch: master
          # Basically wait forever -- we would prefer not to fail deploys and
          # we'll likely never be this backed up.
          time: '10000'
      - checkout
      - set-slack-user-id
      - setup-python-venv:
          determined-common: true
          determined-deploy: true
          executor: determinedai/cimg-base:stable
      - deploy-aws-cluster:
          cluster-id: determined-${CIRCLE_BRANCH////--}
          det-version: ${CIRCLE_SHA1}
          gpu-agent-instance-type: <<parameters.gpu-agent-instance-type>>
          cpu-agent-instance-type: <<parameters.cpu-agent-instance-type>>
          max-dynamic-agents: <<parameters.max-dynamic-agents>>
          enable-cors: <<parameters.enable-cors>>
      - slack/status:
          fail_only: true
          failure_message: ':thisisfine: A \`${CIRCLE_JOB}\` job on branch \`${CIRCLE_BRANCH}\` has failed! Author Email: \`${AUTHOR_EMAIL}\`'
          mentions: "${SLACK_USER_ID}"

  test-e2e-aws:
    parameters:
      cluster-id-prefix:
        type: string
      mark:
        type: string
      gpu-agent-instance-type:
        type: string
        default: p2.xlarge
      cpu-agent-instance-type:
        type: string
        default: m5.large
      max-dynamic-agents:
        type: integer
        default: 1
      parallelism:
        type: integer
        default: 1
      enable-tls:
        type: boolean
        default: false
      slack-mentions:
        type: string
        default: ""
      slack-channel:
        type: string
        default: ""
    docker:
      - image: determinedai/cimg-base:stable
    parallelism: <<parameters.parallelism>>
    steps:
      - checkout
      - set-slack-user-id
      - setup-python-venv:
          determined-common: true
          determined-cli: true
          determined: true
          determined-deploy: true
          extra-requirements-file: "e2e_tests/tests/requirements.txt"
          executor: determinedai/cimg-base:stable
      - when:
          condition: <<parameters.enable-tls>>
          steps:
            - generate-tls-cert
      - setup-aws-cluster:
          cluster-id: <<parameters.cluster-id-prefix>>-$(git rev-parse --short HEAD)-${CIRCLE_BUILD_NUM}-${CIRCLE_NODE_INDEX}
          det-version: ${CIRCLE_SHA1}
          cpu-agent-instance-type: <<parameters.cpu-agent-instance-type>>
          gpu-agent-instance-type: <<parameters.gpu-agent-instance-type>>
          max-dynamic-agents: <<parameters.max-dynamic-agents>>
          master-tls-cert: ${MASTER_TLS_CERT}
          master-tls-key: ${MASTER_TLS_KEY}
          master-cert-name: ${MASTER_CERT_NAME}
      - run-e2e-tests:
          mark: <<parameters.mark>>
          master-host: ${MASTER_HOST}
          master-scheme: ${MASTER_SCHEME:-http}
          master-port: ${MASTER_PORT:-8080}
          master-cert: ${MASTER_TLS_CERT}
          master-cert-name: ${MASTER_CERT_NAME}
      - locate-cloudwatch-logs:
          cluster-id: ${CLUSTER_ID}
      - terminate-aws-cluster:
          cluster-id: ${CLUSTER_ID}
      - store_test_results:
          path: /tmp/test-results/
      - slack/status:
          fail_only: True
          only_for_branches: master
          failure_message: ':thisisfine: A \`<<parameters.mark>>\` E2E GPU job on branch \`${CIRCLE_BRANCH}\` has failed! Author Email: \`${AUTHOR_EMAIL}\`'
          mentions: <<parameters.slack-mentions>>
          channel: <<parameters.slack-channel>>

  test-e2e-gke:
    parameters:
      cluster-id-prefix:
        type: string
      mark:
        type: string
      parallelism:
        type: integer
        default: 1
      gke-version:
        type: string
        default: "1.17.14-gke.1600"
      machine-type:
        type: string
        default: "n1-standard-8"
      num-machines:
        type: integer
        default: 1
      gpu-type:
        type: string
        default: "nvidia-tesla-k80"
      gpus-per-machine:
        type: integer
        default: 1
      region:
        type: string
        default: "us-west1"
      node-locations:
        type: string
        default: "us-west1-b"
      slack-mentions:
        type: string
        default: ""
      slack-channel:
        type: string
        default: ""
    docker:
      - image: determinedai/cimg-base:stable
    parallelism: <<parameters.parallelism>>
    steps:
      - checkout
      - set-slack-user-id
      - setup-python-venv:
          determined-common: true
          determined-cli: true
          determined: true
          extra-requirements-file: "e2e_tests/tests/requirements.txt"
          executor: determinedai/cimg-base:stable
      - setup-gke-cluster:
          cluster-id: <<parameters.cluster-id-prefix>>-$(git rev-parse --short HEAD)-${CIRCLE_BUILD_NUM}-${CIRCLE_NODE_INDEX}
          det-version: ${CIRCLE_SHA1}
          gke-version: <<parameters.gke-version>>
          machine-type: <<parameters.machine-type>>
          num-machines: <<parameters.num-machines>>
          gpu-type: <<parameters.gpu-type>>
          gpus-per-machine: <<parameters.gpus-per-machine>>
          region: <<parameters.region>>
          node-locations: <<parameters.node-locations>>
      - set-google-application-credentials
      - run-e2e-tests:
          mark: <<parameters.mark>>
          master-host: ${MASTER_HOST}
      - terminate-gke-cluster:
          cluster-id: ${CLUSTER_ID}
          region: <<parameters.region>>
      - slack/status:
          fail_only: True
          only_for_branches: master
          failure_message: ':thisisfine: A \`<<parameters.mark>>\` E2E GKE GPU job on branch \`${CIRCLE_BRANCH}\` has failed! Author Email: \`${AUTHOR_EMAIL}\`'
          mentions: <<parameters.slack-mentions>>
          channel: <<parameters.slack-channel>>

  test-e2e-gke-cuda-11:
    parameters:
      cluster-id-prefix:
        type: string
      mark:
        type: string
      parallelism:
        type: integer
        default: 1
      gke-version:
        type: string
        default: "1.18.12-gke.1205"
      machine-type:
        type: string
        default: "a2-highgpu-1g"
      num-machines:
        type: integer
        default: 1
      gpu-type:
        type: string
        default: "nvidia-tesla-a100"
      gpus-per-machine:
        type: integer
        default: 1
      region:
        type: string
        default: "us-central1"
      node-locations:
        type: string
        default: "us-central1-c"
      slack-mentions:
        type: string
        default: ""
      slack-channel:
        type: string
        default: ""
    docker:
      - image: determinedai/cimg-base:stable
    parallelism: <<parameters.parallelism>>
    environment:
      # Using the TF2-only image here is a hack to get more test coverage since TF1 is still the
      # default system-wide. TF1 tests that fail in this configuration should be skipped when the
      # "CUDA" environment variable is set to 11.
      # TODO: (DET-4918): we should ensure a consistent way to have tests that can run against
      # both major TensorFlow versions do so regularly (but not others).
      TF1_GPU_IMAGE: determinedai/environments:cuda-11.0-pytorch-1.7-tf-2.4-gpu-0.9.0
      TF2_GPU_IMAGE: determinedai/environments:cuda-11.0-pytorch-1.7-tf-2.4-gpu-0.9.0
      CUDA: 11
    steps:
      - checkout
      - set-slack-user-id
      - setup-python-venv:
          determined-common: true
          determined-cli: true
          determined: true
          extra-requirements-file: "e2e_tests/tests/requirements.txt"
          executor: determinedai/cimg-base:stable
      - setup-gke-cluster-cuda-11:
          cluster-id: <<parameters.cluster-id-prefix>>-$(git rev-parse --short HEAD)-${CIRCLE_BUILD_NUM}-${CIRCLE_NODE_INDEX}
          det-version: ${CIRCLE_SHA1}
          gke-version: <<parameters.gke-version>>
          machine-type: <<parameters.machine-type>>
          num-machines: <<parameters.num-machines>>
          gpu-type: <<parameters.gpu-type>>
          gpus-per-machine: <<parameters.gpus-per-machine>>
          node-locations: <<parameters.node-locations>>
      - set-google-application-credentials
      - run-e2e-tests:
          mark: <<parameters.mark>>
          master-host: ${MASTER_HOST}
      - terminate-gke-cluster-cuda-11:
          cluster-id: ${CLUSTER_ID}
          zone: <<parameters.node-locations>>
      - slack/status:
          fail_only: True
          only_for_branches: master
          failure_message: ':thisisfine: A \`<<parameters.mark>>\` E2E GKE GPU job on branch \`${CIRCLE_BRANCH}\` has failed! Author Email: \`${AUTHOR_EMAIL}\`'
          mentions: <<parameters.slack-mentions>>
          channel: <<parameters.slack-channel>>

  test-det-deploy:
    parameters:
      mark:
        type: string
      parallelism:
        type: integer
        default: 1
      det-version:
        type: string
    machine:
      image: ubuntu-1604:202004-01
    resource_class: large
    parallelism: <<parameters.parallelism>>
    steps:
      - checkout
      - attach_workspace:
          at: .
      - run: docker load --input build/master.image
      - run: docker load --input build/agent.image

      - run: pyenv global 3.6.10
      - setup-python-venv:
          determined-common: true
          determined-cli: true
          determined: true
          determined-deploy: true
          extra-requirements-file: "e2e_tests/tests/requirements.txt"
          executor: ubuntu-1604:202004-01

      - pull-task-images:
          tf1: True

      - run-det-deploy-tests:
          mark: <<parameters.mark>>
          det-version: <<parameters.det-version>>

workflows:
  lint:
    jobs:
      - build-proto
      - build-and-package-ts-sdk:
          requires:
            - build-proto
      - lint-docs
      - lint-python
      - lint-go
      - lint-react:
          requires:
            - build-and-package-ts-sdk

  test-cli:
    jobs:
      - test-cli:
          matrix:
            parameters:
              executor-name:
                [
                  "python-35",
                  "python-36",
                  "python-37",
                  "python-38",
                  "win/default",
                ]

  test-unit:
    jobs:
      - test-unit-go
      - build-proto
      - build-and-package-ts-sdk:
          requires:
            - build-proto
      - test-unit-react:
          requires:
            - build-and-package-ts-sdk
      - test-unit-harness
      - test-unit-harness-tf2
      - test-examples

  test-intg:
    jobs:
      - test-intg-master
      - test-intg-agent

  test-e2e:
    jobs:
      - build-proto
      - build-and-package-ts-sdk:
          requires:
            - build-proto
      - build-react-preview:
          requires:
            - build-and-package-ts-sdk
      - build-react:
          dev-mode: true
          requires:
            - build-and-package-ts-sdk
      - build-storybook:
          requires:
            - build-and-package-ts-sdk
      - build-docs:
          requires:
            - build-proto
      - build-go
      - package-and-push-system-local:
          requires:
            - build-react
            - build-docs

      - package-and-push-system-dev:
          requires:
            - build-react
            - build-docs
          filters:
            branches:
              ignore:
                - /pull\/.*/

      - test-debian-packaging:
          requires:
            - package-and-push-system-local

      - test-e2e:
          name: test-e2e-tf2
          requires:
            - build-go
          matrix:
            parameters:
              parallelism: [1]
              tf2: [true]
              mark: ["tensorflow2_cpu"]

      - test-e2e:
          name: test-e2e-tf1
          requires:
            - build-go
          matrix:
            parameters:
              parallelism: [1]
              tf1: [true]
              mark: ["tensorflow1_cpu"]

      - test-e2e:
          name: test-e2e-cpu
          requires:
            - build-go
          matrix:
            parameters:
              parallelism: [4]
              tf1: [true]
              mark: ["e2e_cpu"]

      - test-e2e-webui:
          requires:
            - build-and-package-ts-sdk
            - package-and-push-system-local

      - deploy:
          enable-cors: true
          context: aws
          filters:
            branches:
              only:
                - master
          requires:
            - package-and-push-system-dev

      - deploy:
          name: deploy-release-party
          context: aws
          filters:
            branches:
              only:
                - /release-.*/
          requires:
            - package-and-push-system-dev
          matrix:
            parameters:
              gpu-agent-instance-type: ["p2.8xlarge"]
              cpu-agent-instance-type: ["m5.large"]
              max-dynamic-agents: [8]

      - test-e2e-aws:
          name: test-e2e-gpu-parallel
          context: aws
          filters:
            branches:
              only: master
          requires:
            - package-and-push-system-dev
          matrix:
            parameters:
              parallelism: [2]
              gpu-agent-instance-type: ["p2.8xlarge"]
              cpu-agent-instance-type: ["m5.large"]
              cluster-id-prefix: ["parallel"]
              mark: ["parallel"]
              slack-mentions: ["${SLACK_USER_ID}"]

      - test-e2e-aws:
          name: test-e2e-gpu-single
          context: aws
          filters:
            branches:
              only: master
          requires:
            - package-and-push-system-dev
          matrix:
            parameters:
              parallelism: [2]
              cluster-id-prefix: ["e2e-gpu"]
              enable-tls: [true]
              mark: ["e2e_gpu"]
              slack-mentions: ["${SLACK_USER_ID}"]

      - request-dev-deploy:
          type: approval
          filters: *upstream-feature-branch

      - deploy:
          context: aws
          filters: *upstream-feature-branch
          requires:
            - request-dev-deploy
            - package-and-push-system-dev

      - request-gpu-tests:
          type: approval
          filters: *upstream-feature-branch

      - test-e2e-aws:
          name: test-e2e-gpu-parallel
          context: aws
          filters: *upstream-feature-branch
          requires:
            - request-gpu-tests
            - package-and-push-system-dev
          matrix:
            parameters:
              parallelism: [2]
              gpu-agent-instance-type: ["p2.8xlarge"]
              cpu-agent-instance-type: ["m5.large"]
              cluster-id-prefix: ["parallel"]
              mark: ["parallel"]
              slack-mentions: ["${SLACK_USER_ID}"]

      - test-e2e-aws:
          name: test-e2e-gpu-single
          context: aws
          filters: *upstream-feature-branch
          requires:
            - request-gpu-tests
            - package-and-push-system-dev
          matrix:
            parameters:
              parallelism: [2]
              cluster-id-prefix: ["e2e-gpu"]
              enable-tls: [true]
              mark: ["e2e_gpu"]
              slack-mentions: ["${SLACK_USER_ID}"]

      - test-e2e-gke:
          name: test-e2e-gke-single-gpu
          context: gcp
          filters:
            branches:
              only: master
          requires:
            - package-and-push-system-dev
          matrix:
            parameters:
              cluster-id-prefix: ["e2e-gpu"]
              mark: ["e2e_gpu"]
              parallelism: [1]
              slack-mentions: ["${SLACK_USER_ID}"]

      - test-e2e-gke:
          name: test-e2e-gke-parallel
          context: gcp
          filters:
            branches:
              only: master
          requires:
            - package-and-push-system-dev
          matrix:
            parameters:
              cluster-id-prefix: ["parallel"]
              mark: ["parallel"]
              parallelism: [1]
              slack-mentions: ["${SLACK_USER_ID}"]
              machine-type: ["n1-standard-32"]
              gpus-per-machine: [4]
              num-machines: [2]

      - request-k8-tests:
          type: approval
          filters: *upstream-feature-branch

      - request-k8-tests-cuda-11:
          type: approval
          filters: *upstream-feature-branch

      - test-e2e-gke:
          name: test-e2e-gke-single-gpu
          context: gcp
          filters: *upstream-feature-branch
          requires:
            - request-k8-tests
            - package-and-push-system-dev
          matrix:
            parameters:
              cluster-id-prefix: ["e2e-gpu"]
              mark: ["e2e_gpu"]
              parallelism: [1]
              slack-mentions: ["${SLACK_USER_ID}"]

      - test-e2e-gke:
          name: test-e2e-gke-parallel
          context: gcp
          filters: *upstream-feature-branch
          requires:
            - request-k8-tests
            - package-and-push-system-dev
          matrix:
            parameters:
              cluster-id-prefix: ["parallel"]
              mark: ["parallel"]
              parallelism: [1]
              slack-mentions: ["${SLACK_USER_ID}"]
              machine-type: ["n1-standard-32"]
              gpus-per-machine: [4]
              num-machines: [2]

      - test-e2e-gke-cuda-11:
          name: test-e2e-gke-single-gpu-cuda-11
          context: gcp
          filters: *upstream-feature-branch
          requires:
            - request-k8-tests-cuda-11
            - package-and-push-system-dev
          matrix:
            parameters:
              cluster-id-prefix: ["e2e-gpu"]
              mark: ["e2e_gpu"]
              parallelism: [1]
              slack-mentions: ["${SLACK_USER_ID}"]

      - test-e2e-gke-cuda-11:
          name: test-e2e-gke-parallel-cuda-11
          context: gcp
          filters: *upstream-feature-branch
          requires:
            - request-k8-tests-cuda-11
            - package-and-push-system-dev
          matrix:
            parameters:
              cluster-id-prefix: ["parallel"]
              mark: ["parallel"]
              parallelism: [1]
              slack-mentions: ["${SLACK_USER_ID}"]
              machine-type: ["a2-highgpu-4g"]
              gpus-per-machine: [4]
              num-machines: [2]

      - test-det-deploy:
          name: test-det-deploy-local
          requires:
            - package-and-push-system-local
          matrix:
            parameters:
              parallelism: [2]
              mark: ["det_deploy_local"]
              det-version: [$CIRCLE_SHA1]

  nightly:
    triggers:
      - schedule:
          cron: "0 5 * * *"
          filters:
            branches:
              only:
                - master
    jobs:
      - test-e2e-aws:
          name: test-e2e-gpu-nightly
          context: aws
          matrix:
            parameters:
              parallelism: [2]
              cluster-id-prefix: ["nightly"]
              mark: ["nightly"]
              slack-mentions: ["channel"]
              slack-channel: ["ml-ag"]
      - test-e2e-aws:
          name: test-e2e-gpu-distributed
          context: aws
          matrix:
            parameters:
              cluster-id-prefix: ["distributed"]
              mark: ["distributed"]
              gpu-agent-instance-type: ["p2.8xlarge"]
              cpu-agent-instance-type: ["m5.large"]
              max-dynamic-agents: [2]
              slack-mentions: ["channel"]
              slack-channel: ["ml-ag"]

  weekly-cuda-11:
    triggers:
      - schedule:
          cron: "0 0 * * 1"
          filters:
            branches:
              only:
                - master
    jobs:
      - test-e2e-gke-cuda-11:
          name: test-e2e-gke-single-gpu-cuda-11
          context: gcp
          matrix:
            parameters:
              cluster-id-prefix: ["e2e-gpu"]
              mark: ["e2e_gpu"]
              parallelism: [1]
              slack-mentions: ["${SLACK_USER_ID}"]

      - test-e2e-gke-cuda-11:
          name: test-e2e-gke-parallel-cuda-11
          context: gcp
          matrix:
            parameters:
              cluster-id-prefix: ["parallel"]
              mark: ["parallel"]
              parallelism: [1]
              slack-mentions: ["${SLACK_USER_ID}"]
              machine-type: ["a2-highgpu-4g"]
              gpus-per-machine: [4]
              num-machines: [2]

  release:
    jobs:
      - build-proto:
          filters: *release-and-rc-filters
      - build-and-package-ts-sdk:
          requires:
            - build-proto
          filters: *release-and-rc-filters
      - build-react:
          requires:
            - build-and-package-ts-sdk
          context: determined-production
          filters: *release-and-rc-filters
      - build-docs:
          context: determined-production
          filters: *release-and-rc-filters
          requires:
            - build-proto

      - publish-python-package:
          matrix:
            parameters:
              path: ["common", "harness", "cli", "deploy"]
          context: determined-production
          filters: *release-and-rc-filters

      - package-and-push-system-rc:
          requires:
            - build-react
            - build-docs
          context: determined-production
          filters: *rc-filters

      - package-and-push-system-release:
          requires:
            - build-react
            - build-docs
          context: determined-production
          filters: *release-filters

      - publish-docs:
          requires:
            - build-docs
          context: determined-production
          filters: *release-filters

      - upload-try-now-template:
          context: determined-production
          filters: *release-filters
