{
    "train_micro_batch_size_per_gpu": 128,
    "gradient_accumulation_steps": 1,
    "optimizer": {
        "type": "Adam",
        "params": {
            "lr": 1e-3
        }
    },
    "fp16": {
        "enabled": true
    },
    "autotuning": {
        "enabled": true,
        "fast": false,
        "tuner_type": "random",
        "tuner_num_trials": 25,
        "num_tuning_micro_batch_sizes": 5,
        "tuner_early_stopping": 5,
        "metric": "throughput"
    }
}
