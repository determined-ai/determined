# httpPort controls the port at which the listens for connections on.
httpPort: 8080 

# db sets the configurations for the database.
db:
  # To deploy your own postgres DB please provide a hostAddress.
  # Note: if db hostAddress is provided Determined will skip deploying
  # a postgres DB.
  # hostAddress:

  # Required db field. These parameters are required for both your
  # own DB and a Determined DB.
  name: determined
  user: postgres
  password: postgres
  port: 5432

  # Only used for Determined db deployment.
  storageSize: 30Gi

# checkpointStorage controls where checkpoints are stored.
# supported types include `shared_fs`, `gcs`, and `s3.
checkpointStorage:
  # Applicable to all checkpointStorage types.
  saveExperimentBest: 0
  saveTrialBest: 1
  saveTrialLatest: 1


  # Comment out if not using `shared_fs`
  type: shared_fs
  hostPath: /checkpoints

  # For storing in gcs.
  # type: gcs
  # bucket: <bucket_name>

  # For storing in s3.
  # type: s3
  # bucket: <bucket_name>
  # accessKey: <access_key>
  # secretKey: <secret_key>
  # endpointUrl: <endpoint_url>

# This is the number of GPUs there are per machine. Determined uses this information when
# scheduling multi-GPU tasks. Each multi-GPU (distributed training) task will be scheduled as
# a set of `slotsPerTask / slotsPerNode` separate pods, with each pod assigned to `slotsPerNode` GPUs.
# Tasks sizes that are not divisible by `slotsPerNode` are never scheduled. If you have a cluster of
# different size nodes (e.g., 4 and 8 GPUs per node), set the `slotsPerNode` to the smallest
# common denominator.
slotsPerNode:

# Memory and CPU requirements for the master instance should be adjusted for scale.
masterCpuRequest: "4"
masterMemRequest: "8Gi"

## Configure the task container defaults. Tasks include trials, commands, tensorboards notebooks and shells.
## For all task containers, shm_size_bytes and network_mode are configurable. For trials, the
## network interface used by distributed (multi-machine) training and ports used by the NCCL and
## GLOO libraries during distributed training are configurable. These default to auto-discovery and
## random non-privileged ports, respectively.
taskContainerDefaults:
  shmSizeBytes: 4294967296
  # networkMode: bridge
  # dtrainNetworkInterface: <network interface name>
  # ncclPortRange: <MIN:MAX>
  # glooPortRange: <MIN:MAX>

## Configure whether we collect anonymous information about the usage of Determined.
telemetry:
  enabled: true
