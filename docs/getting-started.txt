#################################
 Quickstart for Model Developers
#################################

This quickstart uses the MNIST dataset to demonstrate basic Determined functionality, and walks you
through the steps needed to install Determined, run training jobs, and visualize experiment results
in your browser. Three examples show the scalability and enhanced functionality gained from simple
configuration setting changes:

-  Train on a local, single CPU or GPU.
-  Run a distributed training job on multiple GPUs.
-  Use hyperparameter tuning.

An *experiment* is a training job that consists of one or more variations, or trials, on the same
model. By calling Determined API functions from your training loops, you automatically get metric
frequency output, plots, and checkpointing for every experiment without writing extra code. You can
use the WebUI to view model information, configuration settings, output logs, and training metrics
for all of your experiments.

Each of these quickstart examples uses the same model code and example dataset, differing only in
their configuration settings. For a list of all experiment configuration settings and more detailed
information about each, see :doc:`/training-apis/experiment-config`.

***************
 Prerequisites
***************

Software
========

-  Determined *agent* and *master* nodes must be configured with Ubuntu 16.04 or higher, CentOS 7,
   or macOS 10.13 or higher.

-  Agent nodes must have Docker installed.

-  To run jobs with GPUs, install Nvidia drivers, version 384.81 or higher, on each agent. The
   drivers can be installed as part of a CUDA installation but the rest of the CUDA toolkit is not
   required.

Hardware
========

-  Master node:

   -  At least 4-CPU cores, Intel Broadwell or later. The master node does not require GPUs.
   -  8GB RAM
   -  200GB of free disk space.

-  Agent Node:

   -  At least 2-CPU cores, Intel Broadwell or later.
   -  If you are using GPUs, Nvidia GPUs with compute capability 3.7 or greater are required: K80,
      P100, V100, A100, GTX 1080, GTX 1080 Ti, TITAN, or TITAN XP.
   -  4GB RAM
   -  50GB of free disk space.

Docker
======

For the distributed example that use an agent, install Docker to run containerized workloads. If you
do not already have Docker installed, follow the :doc:`Installing Docker
</sysadmin-deploy-on-prem/requirements>` instructions to install and run Docker on Linux or macOS.

Environment Variables
=====================

To run Determined on a remote master instance, set the remote IP address and port number in the
``DET_MASTER`` environment variable:

.. code:: bash

   export DET_MASTER=<ipAddress>:8080

***************************************
 Install and Deploy Determined Locally
***************************************

To install the Determined library and start a cluster locally, enter:

.. code:: bash

   pip install determined
   det deploy local cluster-up

If your local machine does not have a supported Nvidia GPU, include the ``no-gpu`` option:

.. code:: bash

   pip install determined
   det deploy local cluster-up --no-gpu

******************************
 Quickstart Training Examples
******************************

Download and extract the files used in this quickstart to a local directory:

#. Download link: :download:`mnist_pytorch.tgz </examples/mnist_pytorch.tgz>`.

#. Extract the configuration and model files:

   .. code:: bash

      tar xzvf mnist_pytorch.tgz

You should see the following files in the ``mnist_pytorch`` directory:

.. code::

   adaptive.yaml
   const.yaml
   data.py
   distributed.yaml
   layers.py
   model_def.py
   README.md

Configuration
=============

Each of the YAML-formatted configuration files corresponds to one of the following example
experiments:

+------------------------+------------------------------------------------------+
| Configuration Filename | Example Experiment                                   |
+========================+======================================================+
| ``const.yaml``         | Train a single model on a single GPU/CPU, with       |
|                        | constant hyperparameter values.                      |
+------------------------+------------------------------------------------------+
| ``distributed.yaml``   | Train a single model using multiple, distributed     |
|                        | GPUs.                                                |
+------------------------+------------------------------------------------------+
| ``adaptive.yaml``      | Perform a hyperparameter search using the Determined |
|                        | adaptive hyperparameter tuning algorithm.            |
+------------------------+------------------------------------------------------+

Model and Pipeline Definition
=============================

Although the Python model and data pipeline definition files are not explained in this quickstart,
you might want to review them to see how to call the Determined API from your code:

+------------------+------------------------------------------------------------------------+
| Filename         | Experiment Type                                                        |
+==================+========================================================================+
| ``data.py``      | Model data loading and preparation code.                               |
+------------------+------------------------------------------------------------------------+
| ``layers.py``    | Convolutional layers used by the model.                                |
+------------------+------------------------------------------------------------------------+
| ``model_def.py`` | Model definition and training/validation loops.                        |
+------------------+------------------------------------------------------------------------+

After gaining basic familiarity with Determined tools and operations, you can experiment in your
domain by replacing these files with your model data and code, and setting configuration parameters
for the kind of experiments you want to run.

***********************************
 Run a Single CPU/GPU Training Job
***********************************

This exercise trains a single model for a fixed number of batches, using constant values for all
hyperparameters on a single *slot*. A slot is a CPU or GPU computing device, which the master
schedules to run.

#. In the ``mnist_pytorch`` directory, create an experiment specifying the ``const.yaml``
   configuration file:

   .. code:: bash

      det experiment create const.yaml .

   The last dot notation (.) argument uploads all of the example files to the Determined cluster and
   makes them available in the working, or *context*, directory in which each trial is run.

   You should receive confirmation that the experiment is created:

   .. code:: console

      Preparing files (.../mnist_pytorch) to send to master... 8.6KB and 7 files
      Created experiment 1

   .. tip::

      To automatically stream log messages for the first trial in an experiment to ``stdout``,
      specifying the configuration file and context directory, enter:

      .. code:: bash

         det e create const.yaml . --follow

#. Enter the cluster address in the browser address bar to view experiment progress in the WebUI. If
   you installed locally using the ``det deploy local`` command, the URL is
   ``http://localhost:8080/``. Accept the default ``determined`` username and click **Sign In**. No
   password is required.

   .. image:: /assets/images/qs01b.png
      :width: 704px
      :align: center
      :alt: Dashboard

   The figure shows two experiments. Experiment **3** has **COMPLETED** and experiment **4** is
   still **ACTIVE**. Your experiment number and status can differ depending on how many times you
   run the examples.

#. While an experiment is in the ACTIVE, training state, click the experiment tile to see the
   **Metrics** graph update for your currently defined metrics:

   .. image:: /assets/images/qs04.png
      :width: 704px
      :align: center
      :alt: Metrics graph detail

   In this example, the graph displays the loss.

#. After the experiment completes, click the experiment tile to view the trial page:

   .. image:: /assets/images/qs03.png
      :width: 704px
      :align: center
      :alt: Trial page

   TBD: What is this image showing me that the user needs to know?

With this fundamental understanding of Determined, you are ready to scale to the distributed
environment in the next example.

********************************
 Run a Distributed Training Job
********************************

In the distributed configuration examples, a Determined cluster comprises a master and one or more
agents. The master provides centralized management of the agent resources.

This example requires a Determined cluster with multiple GPUs and, while it does not fully
demonstrate the benefits of distributed training, it does show how to work with additional hardware
resources.

The ``distributed.yaml`` configuration file in this example is the same as the ``const.yaml`` file
in the previous example, except that a ``resources.slots_per_trial`` field is defined and set to
``8``, which is the number of your available GPU resources. The ``slots_per_trial`` value must be
divisible by the number of GPUs per machine. You can change the value to match your hardware
configuration.

#. Create and run the experiment:

   .. code:: bash

      det experiment create distributed.yaml .

   You can also specify a remote master IP address:

   .. code:: bash

      det -m http://<ipAddress>:8080 experiment create distributed.yaml .

#. Enter the cluster address in your browser address bar.

#. Accept the default ``determined`` username and click **Sign In** to view the WebUI dashboard. You
   do not need a password.

#. Click the **Experiment** tile to view the experimentâ€™s trial display.

The loss curve is similar to the single-GPU experiment in the previous exercise but the time to
complete the trial is reduced by about half.

*********************************
 Run a Hyperparameter Tuning Job
*********************************

This example demonstrates hyperparameter search using the ``adaptive.yaml`` configuration file,
which is similar to the ``const.yaml`` file in the first example but includes additional
``hyperparameters`` settings and ``searcher`` parameter changes.

Hyperparameter searches involve multiple trials or model variations per experiment. The parameter
settings tell the search algorithm the ranges to explore for each hyperparameter. This example model
uses a fixed batch size and searches on dropout size, filters, and learning rate. The searcher name
is set to ``adaptive_asha`` and ``max_trials`` is set to ``16``, indicating which search algorithm
to use and how many model configurations to explore.

#. Create and run the experiment:

   .. code:: bash

      det experiment create adaptive.yaml .

#. Enter your cluster address in the browser address bar.

#. Accept the default determined username with no password and click **Sign In** to view the
   dashboard.

#. This can take some time to complete and you can monitor the progress in the WebUI Dashboard.
   Click the **Experiment** tile to access the experiment trial display and notice that more trials
   have started:

   .. image:: /assets/images/qs05.png
      :width: 704px
      :align: center
      :alt: Trials graphic

   Determined runs the number of ``max_trials`` trials and automatically starts new trials as
   resources become available. On a typical laptop, 16 trials should take about 10 minutes to train
   with at least one trial performing at about 98 percent validation accuracy. The hyperparameter
   search halts poorly performing trials.

************
 Learn More
************

For detailed information on administrator tasks and how to install Determined on different
platforms, see:

-  :doc:`/sysadmin-basics/index` for administrator setup tasks.
-  :doc:`/sysadmin-deploy-on-prem/index` for local setup and deployment tasks.
-  :doc:`/sysadmin-deploy-on-aws/index` for AWS deployment.
-  :doc:`/sysadmin-deploy-on-gcp/index` for GCP deployment.
-  :doc:`/sysadmin-deploy-on-k8s/index` for installation and running Determined on Kubernetes.

In the :doc:`/examples` documentation, you can find machine learning models that have been ported to
the Determined APIs. Each example includes a model definition and one or more experiment
configuration files, and instructions on how to run the example.

To learn more about the hyperparameter search algorithm, see the :doc:`Hyperparameter Tuning
</training-hyperparameter/index>` section.

For faster, less structured ways to run a Determined cluster without writing a model, see:

-  :ref:`commands-and-shells`
-  :ref:`notebooks`
