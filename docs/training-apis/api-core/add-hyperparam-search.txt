.. _core-add-hyperparam-search:

###########################
 Add Hyperparameter Search
###########################

This section describes how to add support for hyperparameter search. This lets you run random
searches, grid searches, and hyperband searches, using the Determined "adaptive" searcher.

   .. tip::

      Model definition best practices:

      -  Seed RNGs with the Determined-tracked seed for an experiment to significantly improve the
         ability to reproduce training results.
      -  Separate configuration from code to be able to easily browse configurations and
         interactively configure new experiments.

*************************
 Updates to ``train.py``
*************************

This example training file demonstrates how to add hyperparameter search.

.. code::

       import torch
       from model import build_model, train_model, eval_model
       from data import build_data

   -   BATCH_SIZE=32
   -   LR=0.00001
   -   EPOCHS=50

       def main(context):
   +       seed = context.training.trial_seed
   +       random.seed(seed)
   +       torch.random.manual_seed(seed)

   +       hparams = context.training.hparams

   -       model, loss_fn, opt = build_model(LR)
   +       model, loss_fn, opt = build_model(hparams["learning_rate"])

   -       train_data, eval_data = build_dataset(BATCH_SIZE)
   +       train_data, eval_data = build_dataset(hparams["batch_size"])

           batches_trained = 0

   -       for epoch in range(config.EPOCHS):
   +       epochs_trained = 0
   +       for op in context.searcher.ops():
   +           while epochs_trained < op.length:
                   # train model
                   ...

                   # report training metrics to the master
                   ...

   +               epochs_trained += 1
   +
   +               op.report_progress(epochs_trained)

               # evaluate model
               ...

               # report validation metrics to the master
               ...

   +           op.complete(eval_loss)

           with context.checkpoint.save_path() as path:
               torch.save(model.state_dict(), f"{path]/my_checkpoint")

       if __name__ == "__main__":
           import determined as det
           with det.core.init() as context:
               main(context)

Prefer to configure using the experiment configuration.

Initialize a context object for accessing the Core API.

Seed RNGs based on context-provided seed ... also seed any other RNGs you need to.

Read hyperparameters from the context object.

Keep track of how many batches are trained.

Iterate through searcher operations, which are unitless lengths but not treated as epochs.

Every operation represents an absolute length of training, followed by a validation.

Train model.

Report training metrics to the master.

Track how much is trained.

Update progress in the WebUI.

Evaluate model.

Report validation metrics to the master.

Report evaluation of the ``searcher_metric`` for this operation.

Checkpoint model.

*******************************
 Updates to ``my_config.yaml``
*******************************

You can improve development velocity by moving more information to the configuration. This lets you
quickly reconfigure new models with all of the controls in one place:

.. code::

       entrypoint_script: python3 train.py

   +   hyperparameters:
   +       batch_size:
   +           type: int
   +           minval: 1
   +           maxval: 64
   +       learning_rate:
   +           type: log
   +           base: 10
   +           minval: -5  # 10^-5 = .00001
   +           maxval: -3  # 10^-5 = .001

       searcher:
   -       name: "single"
   +       name: "random"
   -       max_length: 1
   +       max_length: 50
   +
   +       max_trials: 10

Define a hyperparameter search space.

Use a real hyperparameter search instead of the single searcher.

Honor max_length in ``train.py``.
