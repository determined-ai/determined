.. _core-getting-started:

#################
 Getting Started
#################

Assuming you have a simple training script built around Pytorch, you need to provide the following
files:

+---------------+------------------------------------------------+
| File          | Description                                    |
+===============+================================================+
| ``model.py``  | model definition and how to train/evaluate it  |
+---------------+------------------------------------------------+
| ``data.py``   | dataset definition                             |
+---------------+------------------------------------------------+
| ``train.py``  | entry point for training the model             |
+---------------+------------------------------------------------+

The next step is to configure your experiment and submit it to the cluster.

************************
 Training File Examples
************************

``model.py``
============

.. code:: python

   import torch

   def build_model(learning_rate):
       # the model is silly, the real focus is on the Core API
       model = nn.Linear(1, 1, False)
       loss_fn = torch.nn.MSELoss()

       opt = torch.optim.SGD(model.parameters(), lr=learning_rate)

       return model, loss_fn, opt

   def train_model(model, loss_fn, opt, train_data):
       losses = []
       for batch in train_data:
           data, labels = batch
           # forward pass
           pred = model(data)
           loss = loss_fn(pred, labels)
           losses.append(loss)
           # backward pass
           loss.backward()
           opt.step()
           opt.zero()
       # reduce training metrics, simple average
       train_loss = sum(losses)/len(losses)
       return train_loss

   @torch.no_grad
   def eval_model(model, loss_fn, eval_data):
       # Validate model.
       losses = []
       for batch in eval_data:
           data, labels = batch
           pred = model(data)
           loss = loss_fn(pred, labels)
           losses.append(loss)
       val_loss = sum(losses)/len(losses)
       return val_loss

``data.py``
===========

.. code:: python

   import torch

   class OnesDataset(torch.utils.data.Dataset):
       def __len__(self):
           return 2048

       def __getitem__(self, index):
           # return data, labels
           return torch.Tensor([1.0]), torch.Tensor([1.0])

   def build_datasets(batch_size):
       train_data = torch.utils.data.DataLoader(
           OnesDataset(), batch_size=batch_size
       )
       eval_data = torch.utils.data.DataLoader(
           OnesDataset(), batch_size=batch_size
       )
       return train_data, eval_data

``train.py``
============

.. code:: python

   import torch
   from model import build_model, train_model, eval_model
   from data import build_data

   # some configurations
   BATCH_SIZE=32
   LR=0.00001
   EPOCHS=50

   def main():
       model, loss_fn, opt = build_model(LR)
       train_data, eval_data = build_dataset(BATCH_SIZE)

       for epoch in range(config.EPOCHS):
           # train model
           train_loss = model.train_model(model, loss_fn, opt, train_data)
           print(f"after epoch {epoch}, train_loss={train_loss}")

           # evaluate model
           eval_loss = model.eval_model(model, loss_fn, train_data)
           print(f"after epoch {epoch}, eval_loss={eval_loss}")

       # checkpoint model
       path="checkpoint_dir/my_checkpoint"
       torch.save(model.state_dict(), path)


   if __name__ == "__main__":
       main()

*********************************
 Configure and Run an Experiment
*********************************

When you submit your script to the cluster, you already have:

-  single-GPU job scheduling, on-premise or on-cloud, and log tracking and viewing
-  experiment configuration and model tracking, using the WebUI or CLI
-  random seeds definition tracking and interactive experiment labeling

Step 1
======

To submit you job to the cluster, configure an experiment similar to the following
``my_config.yaml`` file:

.. code:: yaml

   entrypoint_script: python3 train.py
   searcher:
       name: "single"
       max_length: 1
   bind_mounts:
     - host_path: /my/path/to/checkpoints
   container_path: ./checkpoint_dir

The ``single`` searcher is specified because hyperparameter search is not used.

Although not specified in the training script, configure the searcher for master.

To save the checkpoint to a persistent location, set up a bind mount so that the checkpoint created
inside the container appears on the host file system.

Step 2
======

Submit the script to the cluster:

.. code:: bash

   det experiment create my_config.yaml . -f

The ``-f`` option means "follow logs", which print to your terminal. The ``.`` argument is the model
directory passed to the cluster, which is the current directory that contains your model files.
