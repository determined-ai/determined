.. _resource-pools:

################
 Resource Pools
################

To run tasks such as experiments or notebooks, Determined needs to have
resources (CPUs, GPUs) on which to run the tasks. However, different
tasks have different resource requirements and, given the cost of GPU
resources, it's important to choose the right resources for specific
goals so that you get the most value out of your money. For example, you
may want to run your training on beefy V100 GPU machines, while you want
your Tensorboards to run on cheap CPU machines with minimal resources.

Determined has the concept of a *resource pool*, which is a collection
of identical resources that are located physically close to each other.
Determined allows you to configure your cluster to have multiple
resource pools and to assign tasks to a specific resource pool, so that
you can use different sets of resources for different tasks. Each
resource pool handles scheduling and instance provisioning
independently.

When you configure a cluster, you set which pool is the default for CPU
tasks and which pool is the default for GPU tasks. CPU-only tasks such
as Tensorboards will run on the default CPU pool unless you specify that
they should run in a different pool when launching the task. Tasks which
require a slot, such as experiments or GPU-notebooks, will use the
default GPU pool unless otherwise specified. For this reason we
recommend that you always create a cluster with at least two pools, one
with low-cost CPU instances for CPU-only tasks and one with GPU
instances for GPU tasks. This is the default setup when launching a
cluster on AWS or GCP via ``det deploy``.

Here are some scenarios where it can be valuable to use multiple
resource pools:

-  *Use GPU for training while using CPUs for TensorBoard.*

   You create one pool, ``aws-v100``, that provisions ``p3dn.24xlarge``
   instances (large V100 EC2 instances) and another pool, ``aws-cpu``
   that provisions ``m5.large`` instances (small and cheap CPU
   instances). You train your experiments using the ``aws-v100`` pool,
   while you run your Tensorboards in the ``aws-cpu`` pool. When your
   experiments complete, the ``aws-v100 pool`` can scale down to zero to
   save money, but you can continue to run your TensorBoard. Without
   resource pools, you would have needed to keep a ``p3dn.24xlarge``
   instance running to keep the TensorBoard alive. By default
   Tensorboard will always run on the default CPU pool.

-  *Use GPUs in different availability zones on AWS.*

   You have one pool ``aws-v100-us-east-1a`` that runs ``p3dn.24xlarge``
   in the ``us-east-1a`` availability zone and another pool
   ``aws-v100-us-east-1b`` that runs ``p3dn.24xlarge`` instances in the
   ``us-east-1b`` availability zone. You can launch an experiment into
   ``aws-v100-us-east-1a`` and, if AWS does not have sufficient
   ``p3dn.24xlarge`` capacity in that availability zone, you can launch
   the experiment in ``aws-v100-us-east-1b`` to check if that
   availability zone has capacity. Note that currently the "AWS does not
   have capacity" notification is only visible in the master logs, not
   on the experiment itself.

-  *Use spot/preemptible instances and fall back to on-demand if
   needed.*

   You have one pool ``aws-v100-spot`` that you use to try to run
   training on spot instances and another pool ``aws-v100-on-demand``
   that you fall back to if AWS does not have enough spot capacity to
   run your job. Determined will not switch from spot to on-demand
   instances automatically, but by configuring resource pools
   appropriately, it should be easy for users to select the appropriate
   pool depending on the job they want to run and the current
   availability of spot instances in the AWS region they are using. For
   more information on using spot instances, refer to :ref:`aws-spot`.

-  *Use cheaper GPUs for prototyping on small datasets and expensive GPU
   for training on full datasets.*

   You have one pool with less expensive GPUs that you use for initial
   prototyping on small data sets and another pool that you use for
   training more mature models on large datasets.

*************
 Limitations
*************

Currently resource pools are completely independent from each other so
it is not possible to launch an experiment that tries to use one pool
and then falls back to another one if a certain condition is met. You
will need to manually decide to shift an experiment from one pool to
another.

We do not currently allow a cluster to have resource pools in multiple
AWS/GCP regions or across multiple cloud providers. If the master is
running in one AWS/GCP region, all resource pools must also be in that
AWS/GCP region.

If you create a task that needs slots and specify a pool that will never
have slots (i.e. a pool with CPU-only instances), that task can never
get scheduled. Currently that task will appear to be PENDING
permanently.

We are constantly working to improve Determined and would love to hear
your feedback either through GitHub issues or in our community Slack.

***************************
 Setting Up Resource Pools
***************************

Resource pools are configured via the :ref:`master-configuration`. For
each resource pool, you can configure scheduler and provider
information.

If you are using static resource pools and launching agents by hand, you
will need to update the :ref:`agent-configuration` to specify which
resource pool the agent should join.

*************************************
 Launching Tasks Into Resource Pools
*************************************

When creating a task, the job configuration file has a section called
"resources". You can set the ``resource_pool`` subfield to specify the
``resource_pool`` that a task should be launched into.

.. code:: yaml

   resources:
       resource_pool: pool1

If this field is not set, the task will be launched into one of the two
default pools defined in the :ref:`master-configuration`. Experiments
will be launched into the default GPU pool. Tensorboards will be
launched into the default CPU pool. Commands, Shells, and Notebooks that
request a slot (which is the default behavior if the ``resources.slots``
field is not set) will be launched into the default GPU pool. Commands,
Shells, and Notebooks that explicitly request 0 slots (for example the
"Launch CPU-only Notebook" button in the Web UI) will use the CPU pool.
